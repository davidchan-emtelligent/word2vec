bmc genomics bmc genomics bmc genomics 1471 - 2164 biomed central london 28984181 5629589 4020 10.1186 / s12864 - 017 - 4020 - z research optimal choice of word length when comparing two markov sequences using a chi2 - statistic bai xin xbai10 @ fudan.edu.cn 1 tang kujin kujin @ usc.edu 2 ren jie renj @ usc.edu 2 waterman michael msw @ usc.edu 12 sun fengzhu fsun @ usc.edu 12 1 0000 0001 0125 2443grid.8547.ecentre for computational systems biology , school of mathematical sciences , fudan university , shanghai , china 2 0000 0001 2156 6853grid.42505.36molecular and computational biology program , university of southern california , los angeles , california usa 3 10 2017 3 10 2017 2017 18 suppl 6 publication of this supplement has not been supported by sponsorship .
information about the source of funding for publication charges can be found in the individual articles .
the articles have undergone the journal 's standard peer review process for supplements .
the supplement editors declare that they have no competing interests.732 ( c ) the author ( s ) 2017 open access this article is distributed under the terms of the creative commons attribution 4.0 international license ( http :// creativecommons.org / licenses / by / 4.0 /) , which permits unrestricted use , distribution , and reproduction in any medium , provided you give appropriate credit to the original author ( s ) and the source , provide a link to the creative commons license , and indicate if changes were made .
the creative commons public domain dedication waiver ( http :// creativecommons.org / publicdomain / zero / 1.0 /) applies to the data made available in this article , unless otherwise stated .
background alignment - free sequence comparison using counts of word patterns ( grams , k - tuples ) has become an active research topic due to the large amount of sequence data from the new sequencing technologies .
genome sequences are frequently modelled by markov chains and the likelihood ratio test or the corresponding approximate chi 2 - statistic has been suggested to compare two sequences .
however , it is not known how to best choose the word length k in such studies .
results we develop an optimal strategy to choose k by maximizing the statistical power of detecting differences between two sequences .
let the orders of the markov chains for the two sequences be r 1 and r 2 , respectively .
we show through both simulations and theoretical studies that the optimal k = max ( r 1,r 2 )+ 1 for both long sequences and next generation sequencing ( ngs ) read data .
the orders of the markov chains may be unknown and several methods have been developed to estimate the orders of markov chains based on both long sequences and ngs reads .
we study the power loss of the statistics when the estimated orders are used .
it is shown that the power loss is minimal for some of the estimators of the orders of markov chains .
conclusion our studies provide guidelines on choosing the optimal word length for the comparison of markov sequences .
electronic supplementary material the online version of this article ( doi : 10.1186 / s12864 - 017 - 4020 - z ) contains supplementary material , which is available to authorized users .
keywords markov chain alignment - free genome comparison statistical power ngs the international conference on intelligent biology and medicine ( icibm ) 2016icibm 2016 : genomicshouston , tx , usa08 - 10 december 2016issue - copyright - statement ( c ) the author ( s ) 2017 background the comparison of genome sequences is important for understanding their relationships .
the most widely used methods are alignment based algorithms such as the smith - waterman algorithm [ 1 ] , blast [ 2 ] , blat [ 3 ] , etc .
in such studies , homologous genes among the genomes are identified , aligned , and then their relationships inferred using phylogenetic analysis tools to obtain gene trees .
a consensus tree combining the gene trees from all the homologous genes is used to represent the relationship among the genomes .
however , non - conserved regions form large fractions of most genomes and they also contain information about the relationships among the sequences .
most alignment based methods do not consider the non - conserved regions resulting in loss of information .
another drawback of the alignment based method is the extremely long time needed for the analysis , especially when the number of genome sequences is large. with the development of new sequencing technologies , a large number of genome sequences are now available and many more will be generated .
to overcome the challenges facing alignment based methods for the study of genome sequence relationships , several alignment - free sequence comparison methods have been developed as reviewed in [ 4 , 5 ] .
most of the methods use the counts of word patterns within the sequences [ 6 - 12 ] .
one important problem is the determination of word length used for the comparison of sequences .
several investigators addressed this issue using simulation studies or empirical data [ 13 - 15 ] .
wu et al .
[ 15 ] investigated the performance of euclidian distance , standardized euclidian distance , and symmetric kullback - leibler discrepancy ( sk - ld ) for alignment free genome comparison .
for a given dissimilarity measure , wu et al .
[ 15 ] simulated the evolution of two sequences with different mutation rates and chose the word length that yielded the highest spearman correlation between the dissimilarity measure and the mutation rate .
they showed that sk - ld performed well and the optimal word length increases with the sequence length .
using a similar approach , foret et al .
[ 14 ] studied the optimal word length for d 2 that measures the number of shared words between two sequences [ 8 ] .
sims et al .
[ 13 ] suggested a range for the optimal word length using alignment - free genome comparison with sk - ld. markov chains ( mc ) have been widely used to model molecular sequences to solve several problems including the enrichment and depletion of certain word patterns [ 16 ] , prediction of occurrences of long word patterns from short patterns [ 17 , 18 ] , and the detecting of signals in introns [ 19 ] .
narlikar et al .
[ 20 ] showed the importance of using appropriate markov models on phylogenetic analysis , assignment of sequence fragments to different genomes in metagnomic studies , motif discovery , and functional classification of promoters .
in this paper , we consider the comparison of two sequences modelled using markov chains [ 11 , 12 ] as a hypothesis testing problem .
the null hypothesis is that the two sequences are generated by the same markov chain .
the alternative hypothesis is that they are generated by different markov chains .
we investigate a log - likelihood ratio statistic for testing the hypotheses and its corresponding chi 2 - statistic based on the counts of word patterns in the sequences .
the details of the statistics are given in " the likelihood ratio statistic and the chi2 - statistic for comparing two markov sequences " subsection .
we use statistical power of the test statistic under the alternative hypothesis to evaluate its performance .
we will study the following questions .
a ) what is the optimal word length k yielding the highest power of the chi 2 - statistic ?
b ) how do the estimated orders of the markov sequences , sequence length , word length , and sequencing error rate impact the power of the chi 2 - statistic ?
c ) for ngs read data , what is the distribution of the chi 2 - statistic under the null hypothesis ?
( d ) do the conclusions from ( a ) and ( b ) still hold for ngs reads ?
methods alignment - free comparison of two long markov sequences we study alignment - free comparison of two long markov sequences using counts of word patterns .
we first introduce the likelihood ratio [ 11 , 12 ] and corresponding chi 2 - statistic .
we show theoretically and by simulations that the optimal word length is k = max { r 1,r 2 }+ 1 , where r 1 and r 2 are the orders of the two markov sequences .
we then study the effects of sequence length , word length , and estimated orders of mcs on the power of the chi 2 - statistic .
the likelihood ratio statistic and the chi2 - statistic for comparing two markov sequences given two markov sequences a 1 and a 2 , we want to test if the two sequences follow the same mc , that is , if their transition probability matrices are the same .
we formulate this as a hypothesis testing problem .
the null hypothesis h 0 is that the two sequences are generated from the same mc. the alternative hypothesis h 1 is that the two sequences are generated from mcs with different transition probability matrices .
to test the hypotheses , we use a likelihood ratio test statistic .
since we may not know the orders of mcs , we use counts of word patterns of length k ( k >= 1 ) to test if the two sequences are from the same mc of order k - 1 as in [ 11 ] .
the basic formulation of the problem can be described as follows .
let \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ mathbf { a }_{ s } = a _{ s,1 } a _{ s,2 } \ cdots \ cdots a _{ s , l _{ s }},\ \ s = 1 , 2 , $$ \ end { document } as = as,1as,2 ...... as,ls,s = 1,2 , where l s is the length of the s - th sequence and a s,i , 1 <= i <= l s is the letter of the sequence at the i - th position .
to derive the likelihood ratio test , we assume that both sequences follow mcs of order k - 1 .
the probability of the s - th sequence is 1 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} p (\ mathbf { a }_{ s }) &=& \ pi ^{( s )}_{ a _{ s,1 } a _{ s,2 } \ cdots a _{ s,k - 1 }} \ prod _{ i = k }^{ l _{ s }} t ^{( s )}\ left ( a _{ s , i - k + 1 } \ cdots a _{ s , i - 1 } , a _{ s , i }\ right ) \\ &=& \ pi ^{( s )}_{ a _{ s,1 } a _{ s,2 } \ cdots a _{ s,k - 1 }} \ prod _{\ mathbf { w }} \ left ( t ^{( s )}\ left (\ mathbf { w }^{ - } , w _{ k }\ right )\ right )^{ n ^{( s )}_{\ mathbf { w }}} , \ end { array } $$ \ end { document } p ( as )= pias,1as,2 ... as,k - 1 ( s ) producti = klst ( s ) as,i - k + 1 ... as,i - 1,as,i = pias,1as,2 ... as,k - 1 ( s ) productwt ( s ) w - , wknw ( s ) , where w = w 1 w 2 ... w k is any word pattern of length k , w - = w 1 w 2 ... w k - 1 ( the last letter is removed ) , \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ n ^{( s )}_{\ mathbf { w }}$\ end { document } nw ( s ) is the number of occurrences of word w , and t ( s )( w - , w k ) is the ( k - 1 ) - th order transition probability from w - to w k in the s - th sequence , and pi ( s ) is the initial distribution. from this equation , it is easy to show that the maximum likelihood estimate of t ( s )( w - , w k ) is \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ hat { t }^{( s )}(\ mathbf { w }^{ - } , w _{ k })= \ frac { n ^{( s )}_{\ mathbf { w }}}{ n ^{( s )}_{\ mathbf { w }^{ - }}} .
$$ \ end { document } t ^( s )( w - , wk )= nw ( s ) nw - ( s ) .
therefore , we can obtain the maximum likelihood for the s - th sequence \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { p }(\ mathbf { a }_{ s })$\ end { document } p ^( as ) by replacing t ( s )( w - , w k ) with \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { t }^{( s )}(\ mathbf { w }^{ - } , w _{ k })$\ end { document } t ^( s )( w - , wk ) in equation ( 1 ) .
the likelihood of both sequences under the alternative hypothesis h 1 is 2 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $${} p _{ 1 }\ !
= \ prod _{ s = 1 }^{ 2 }\ !
\ hat { p }(\ mathbf { a }_{ s })\ !
= \ prod _{ s = 1 }^{ 2 } \ pi ^{( s )}_{ a _{ s,1 } a _{ s,2 } \ cdots a _{ s,k - 1 }} \ prod _{\ mathbf { w }} \ left (\ hat { t }^{( s )}\ left (\ mathbf { w }^{ - } , w _{ k }\ right )\ right )^{ n ^{( s )}_{\ mathbf { w }}} .
$$ \ end { document } p1 = products = 12p ^( as )= products = 12pias,1as,2 ... as,k - 1 ( s ) productwt ^( s ) w - , wknw ( s ) .
under the null hypothesis h 0 , the transition matrices for the two sequences are the same .
using the same argument as above , we can show that the maximum likelihood estimate of the common transition probability t ( w - , w k ) is given by \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ hat { t }(\ mathbf { w }^{ - } , w _{ k }) = \ frac { n ^{( - )}_{\ mathbf { w }}}{ n ^{( - )}_{\ mathbf { w }^{ - }}} , $$ \ end { document } t ^( w - , wk )= nw ( - ) nw - ( - ) , where \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ n ^{( - )}_{\ mathbf { w }} = \ sum _{ s = 1 }^{ 2 } n ^{( s )}_{\ mathbf { w }}$\ end { document } nw ( - )= sums = 12nw ( s ) .
then the probability , p 0 , of both sequences can be estimated similarly as in eq .
( 2 ) .
the log - likelihood ratio statistic is given by ( ignoring the first k - 1 bases in each sequence ) 3 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} \ log ( p _{ 1 }/ p _{ 0 }) & = & \ sum _{ s = 1 }^{ 2 } \ sum _{ w _{ 1 } w _{ 2 } \ cdots w _{ k - 1 }} \ sum _{ w _{ k }} n ^{( s )}_{\ mathbf { w }} \ log \ left (\ frac {\ hat { t }^{( s )}(\ mathbf { w }^{ - } , w _{ k })}{\ hat { t }(\ mathbf { w }^{ - } , w _{ k })} \ right ) \\ & = & \ sum _{ s = 1 }^{ 2 } \ sum _{ w _{ 1 } w _{ 2 } \ cdots w _{ k - 1 }} \ sum _{ w _{ k }} n ^{( s )}_{\ mathbf { w }} \ log \ left (\ frac { n ^{( s )}_{\ mathbf { w }} \ times n ^{( - )}_{\ mathbf { w }^{ - }}}{ n ^{( s )}_{\ mathbf { w }^{ - }} \ times n ^{( - )}_{\ mathbf { w }}} \ right )\\ \ end { array } $$ \ end { document } log ( p1 / p0 )= sums = 12sumw1w2 ... wk - 1sumwknw ( s ) logt ^( s )( w - , wk ) t ^( w - , wk )= sums = 12sumw1w2 ... wk - 1sumwknw ( s ) lognw ( s ) xnw - ( - ) nw - ( s ) xnw ( - ) the above statistic has an approximate chi 2 - distribution as the lengths of both sequences become large [ 21 , 22 ] .
it has been shown that twice the log - likelihood ratio statistic has the same approximate distribution as the following chi 2 - statistic [ 11 ] defined by 4 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ s _{ k } = \ sum _{ s = 1 }^{ 2 } \ sum _{ w _{ 1 } w _{ 2 } \ cdots w _{ k - 1 }} \ sum _{ w _{ k }} \ frac {\ left ( n ^{( s )}_{\ mathbf { w }} - n ^{( s )}_{\ mathbf { w }^{ - }} n ^{( - )}_{\ mathbf { w }}/ n ^{( - )}_{\ mathbf { w }^{ - }} \ right )^{ 2 }}{ n ^{( s )}_{\ mathbf { w }^{ - }} n ^{( - )}_{\ mathbf { w }}/ n ^{( - )}_{\ mathbf { w }^{ - }}} .
$$ \ end { document } sk = sums = 12sumw1w2 ... wk - 1sumwknw ( s ) - nw - ( s ) nw ( - )/ nw - ( - ) 2nw - ( s ) nw ( - )/ nw - ( - ) .
since 2 log ( p 1 / p 0 ) and s k are approximately equal , in our study , we use the measure s k for sequence comparison .
to test if two independent identically distributed ( i.i.d ) sequences ( r = 0 ) have the same nucleotide frequencies , we set k = 1 , \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ n ^{( s )}_{\ mathbf { w }^{ - }} = l _{ s } , ~ s = 1 , 2 $\ end { document } nw - ( s )= ls,s = 1,2 , \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ n ^{( - )}_{\ mathbf { w }^{ - }} = l _{ 1 } + l _{ 2 },$\ end { document } nw - ( - )= l1 + l2 , and s 1 is calculated by 5 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ s _{ 1 } = \ sum _{\ mathbf { w }} \ frac { l _{ 1 } l _{ 2 } \ left ( p _{\ mathbf { w }}^{( 1 )} - p _{\ mathbf { w }}^{( 2 )}\ right )^{ 2 }}{ l _{ 1 } p _{\ mathbf { w }}^{( 1 )} + l _{ 2 } p _{\ mathbf { w }}^{( 2 )} } , $$ \ end { document } s1 = sumwl1l2pw ( 1 ) - pw ( 2 ) 2l1pw ( 1 )+ l2pw ( 2 ) , where w is a nucleotide and the summation is over all the nucleotides , \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ p _{\ mathbf { w }}^{( s )} = n _{\ mathbf { w }}^{( s )}/ l _{ s }$\ end { document } pw ( s )= nw ( s )/ ls , and l s is the length of the s - th sequence .
estimating the order of a mc sequence we usually do not know the order , r , of the mc corresponding to each sequence and it needs to be estimated from the data .
several methods have been developed to estimate the order of a mc including those based on the akaike information criterion ( aic ) [ 23 ] and bayesian information criterion ( bic ) [ 24 ] .
the aic and bic for a markov sequence of length l are defined by \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} \ text { aic }( k )&=& - 2 \ sum _{\ mathbf { w }\ in \ mathcal { a }^{ k + 1 }} n _{\ mathbf { w }}\ log \ frac { n _{\ mathbf { w }}}{ n _{\ mathbf { w ^{ - }}}}+ 2 ( c - 1 ) c ^{ k },\\ \ text { bic }( k )&=& - 2 \ sum _{\ mathbf { w }\ in \ mathcal { a }^{ k + 1 }} n _{\ mathbf { w }}\ log \ frac { n _{\ mathbf { w }}}{ n _{\ mathbf { w ^{ - }}}}+( c - 1 ) c ^{ k } \ log ( l - k + 1 ) , \ end { array } $$ \ end { document } aic ( k )= - 2sumwinak + 1nwlognwnw - + 2 ( c - 1 ) ck,bic ( k )= - 2sumwinak + 1nwlognwnw - +( c - 1 ) cklog ( l - k + 1 ) , where c is the alphabet size .
the estimators of the order of a markov sequence based on aic and bic are given by 6 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} \ hat { r }_{\ text { aic }}=\ arg \ min _{ k } aic ( k ) , \ end { array } $$ \ end { document } r ^ aic = argminkaic ( k ) , 7 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} \ hat { r }_{\ text { bic }}=\ arg \ min _{ k } bic ( k ) .
\ end { array } $$ \ end { document } r ^ bic = argminkbic ( k ) .
peres and shields [ 25 ] proposed the following estimator for the order of a markov chain 8 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ hat { r }_{ ps }=\ arg \ max _{ k } \ left \{ \ frac {\ delta ^{ k }}{\ delta ^{ k + 1 }} \ right \} - 1 , $$ \ end { document } r ^ ps = argmaxkdeltakdeltak + 1 - 1 , where \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ delta ^{ k } = \ max _{\ mathbf { w }\ in \ mathcal { a }^{ k }} | n _{\ mathbf { w }} - e _{\ mathbf { w }}| , $$ \ end { document } deltak = maxwinak | nw - ew | , and \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ mathcal { a }$\ end { document } a is the set of all alphabet and \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ e _{\ mathbf { w }}=\ frac { n _{\ mathbf { - w }} n _{\ mathbf { w - }} }{ n _{\ mathbf { - w - }}}$\ end { document } ew = n - wnw - n - w - is the expectation of word w estimated by a k - 2 - th order mc. based on similar ideas as in [ 25 ] , ren et al .
[ 26 ] proposed several methods to estimate the order of a mc based on \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ t _{ k } = \ sum \ limits _{\ mathbf { w }\ in \ mathcal { a }^{ k }}\ frac {( n _{\ mathbf { w }} - e _{\ mathbf { w }})^{ 2 }}{ e _{\ mathbf { w }}},\ qquad \ text { where }\ quad e _{\ mathbf { w }}=\ frac { n _{\ mathbf { - w }} n _{\ mathbf { w - }}}{ n _{\ mathbf { - w - }}} .
$$ \ end { document } tk = sumwinak ( nw - ew ) 2ew,whereew = n - wnw - n - w - . the statistic t k has an approximate chi 2 - distribution with df k =( c - 1 ) 2 c k - 2 degrees of freedom when k >= r + 2 [ 21 , 22 , 27 , 28 ] .
when k < r + 2 , t k will be large if the sequence is long , while t k should be moderate when k >= r + 2 .
based on this idea , we can estimate the order of the mc by 9 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ hat { r }_{ t } = \ arg \ min _{ k } \ left \{\ frac { t _{ k + 1 }}{ t _{ k }} \ right \} - 1 .
$$ \ end { document } r ^ t = argminktk + 1tk - 1 .
instead of using t k directly , we can calculate the corresponding p - value \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} p _{ k }= p ( t _{ k } \ geq t _{ k })= p \ left (\ chi ^{ 2 }_{ df _{ k }} \ geq t _{ k }\ right ) , \ end { array } $$ \ end { document } pk = p ( tk >= tk )= pchidfk2 >= tk , where t k is the observed value of t k based on the long sequence .
since t k is generally large when k <= r + 1 and thus p k should be small , while p k is moderate when k >= r + 2 .
based on this idea , we can estimate the order of a mc by 10 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ hat { r }_{ p }=\ arg \ min _{ k } \ left \{ \ frac {\ log ( p _{ k + 1 })}{\ log ( p _{ k })} \ right \} - 1 .
$$ \ end { document } r ^ p = argminklog ( pk + 1 ) log ( pk ) - 1 .
it is also possible to estimate the order of a mc based on the counts of individual word patterns .
let \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} z _{\ mathbf { w }}=\ frac { n _{\ mathbf { w }} - e _{\ mathbf { w }}}{\ hat {\ sigma }_{\ mathbf { w }}} , \ end { array } $$ \ end { document } zw = nw - ewsigma ^ w , where \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ \ hat {\ sigma }^{ 2 }_{\ mathbf { w }} = e _{\ mathbf { w }} \ left ( 1 - \ frac { n _{ - \ mathbf { w }}}{ n _{ - \ mathbf { w } - }} \ right ) \ left ( 1 - \ frac { n _{\ mathbf { w } - }}{ n _{ - \ mathbf { w } - }}\ right )$\ end { document } sigma ^ w2 = ew1 - n - wn - w - 1 - nw - n - w - with \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ e _{\ mathbf { w }} = \ frac { n _{\ mathbf { - w }} n _{\ mathbf { w - }} }{ n _{\ mathbf { - w - }}}.$\ end { document } ew = n - wnw - n - w - . it has been shown that , for every word w , z w is approximately normally distributed when k >= r + 2 .
when the sequence is long , we expect z max ( k )= maxw ,| w |= k | z w | to be large when k <= r + 1 , while it is moderate when k >= r + 2 .
similar to the ideas given above , we can estimate the order of the mc by 11 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ \ hat { r }_{ z } = \ arg \ min _{ k } \ left \{\ frac { z _{\ max }( k + 1 )}{ z _{\ max }( k )} \ right \} - 1 .
$$ \ end { document } r ^ z = argminkzmax ( k + 1 ) zmax ( k ) - 1 .
we are interested in knowing the power loss of the chi 2 - statistic when any of the estimated orders of the two sequences are used for the comparison of mc sequences .
alignment - free comparison of two markov sequences based on ngs reads we then investigate the comparison of sequences based on ngs reads .
we first extend the chi 2 - statistic in eq .
( 4 ) to be applicable to ngs reads .
we then extend the methods for estimating the order of mc sequences for long sequences to be applicable to ngs reads .
finally , we study the optimal word length for genome comparison based on ngs reads and investigate the effect of sequence length , read length , distributions of reads along the genome , and sequencing errors on the power of the statistic .
alignment - free dissimilarity measures for comparing markov sequences based on ngs reads next generation sequencing ( ngs ) technologies are widely used to sequence genomes .
instead of whole genome sequences , ngs data consists of short reads with lengths ranging from 100 bps to several hundred base pairs depending on the sequencing technologies .
since the reads are randomly chosen from the genomes , some regions can be sequenced multiple times while other regions may not be sequenced .
the log - likelihood ratio statistic in eq .
( 3 ) for long sequences cannot be directly extended to ngs reads because of the dependence of the overlapping reads .
on the other hand , the chi 2 - statistic in eq .
( 4 ) depends only on word counts in the two sequences , and thus can be easily extended to ngs read data .
we replace n w in eq .
( 4 ) by \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ n ^{ r }_{\ mathbf { w }}$\ end { document } nwr , the number of occurrences of word pattern w among the ngs reads , to obtain a new statistic , 12 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} s _{ k }^{ r } &=& \ sum _{ s = 1 }^{ 2 } \ sum _{ w _{ 1 } w _{ 2 } \ cdots w _{ k - 1 }} \ sum _{ w _{ k }} \ frac {\ left ( n ^{ r ( s )}_{\ mathbf { w }} - n ^{ r ( s )}_{\ mathbf { w }^{ - }} n ^{ r ( - )}_{\ mathbf { w }}/ n ^{ r ( - )}_{\ mathbf { w }^{ - }} \ right )^{ 2 }}{ n ^{ r ( s )}_{\ mathbf { w }^{ - }} n ^{ r ( - )}_{\ mathbf { w }}/ n ^{ r ( - )}_{\ mathbf { w }^{ - }}} , \\ \ end { array } $$ \ end { document } skr = sums = 12sumw1w2 ... wk - 1sumwknwr ( s ) - nw - r ( s ) nwr ( - )/ nw - r ( - ) 2nw - r ( s ) nwr ( - )/ nw - r ( - ) , 13 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$\ begin { array }{@{} rcl @{}} s _{ 1 }^{ r } &=& \ sum _{\ mathbf { w }} \ frac { l _{ 1 } l _{ 2 } \ left ( p _{\ mathbf { w }}^{ r ( 1 )} - p _{\ mathbf { w }}^{ r ( 2 )}\ right )^{ 2 }}{ l _{ 1 } p _{\ mathbf { w }}^{ r ( 1 )} + l _{ 2 } p _{\ mathbf { w }}^{ r ( 2 )} } .
\ end { array } $$ \ end { document } s1r = sumwl1l2pwr ( 1 ) - pwr ( 2 ) 2l1pwr ( 1 )+ l2pwr ( 2 ) .
we will use \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr to measure the dissimilarity between the two sequences .
estimating the order of a markov sequence based on ngs reads we next extend the estimators of the order of a mc in " estimating the order of a mc sequence " subsection to ngs reads .
the estimators r aic and r bic cannot be directly calculated because the likelihood of the reads is hard to calculate due to the potential overlaps among the reads .
on the other hand , the other remaining estimators in " estimating the order of a mc sequence " subsection , r ps , r s,r p , and r z , depend only on the word counts and we can just replace n w in these eqs. by \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ n ^{ r }_{\ mathbf { w }}$\ end { document } nwr for the ngs data .
for simplicity of notation , we will continue to use the same notation as that in " estimating the order of a mc sequence " subsection for the corresponding estimators .
similar to the study of long sequences , we investigate the power loss of the statistic \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr when the estimated orders of the sequences are used to compare the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr when the true orders of the sequences are used .
results optimal word length for the comparison of markov sequences using the chi2 - statistic the following theorem gives the optimal word length for the comparison of two sequences using the chi 2 - statistics given in eqs .
4 and ( 5 ) .
the theoretical proof is given in the additional file 1 .
theorem 1 consider two markov sequences of orders r 1 and r 2 , respectively .
we test the alternative hypothesis h 1 : the transition matrices of the two markov sequences are different , versus the null hypothesis h 0 : the transition probability matrices are the same , using the chi 2 - statistic in eqs .
( 4 ) and ( 5 ) .
then the power of the chi 2 - statistic under the alternative hypothesis is maximized when the word length k = max { r 1,r 2 }+ 1 .
in the following , we present simulation results to show the power of the statistic s k in eqs .
( 4 ) and ( 5 ) for different values of sequence length and word pattern length .
we simulated two markov sequences a 1 and a 2 with different transition matrices and then calculated the distributions of the chi 2 - statistic .
we set the length of both sequences to be the same l : 10 , 20 and 30 kbps , respectively , and started the sequences from the stationary distribution .
we simulated mcs of first order and second order , respectively .
tables 1 and 2 show the transition probability matrices of ( a ) the first and ( b ) the second order transition matrices we used in the simulations .
here we present simulation results based on transition matrices from tables 1 and 2 for simplicity .
we also tried other transition matrices and the conclusions were the same .
table 1 the transition probability matrix of the first order markov chain in our simulation studies a c g t a 0.1 0.2 0.3 0.4 c 0.2 0.3 0.4 0.1 g 0.3 0.4 0.1 0.2 t 0.4 0.1 0.2 0.3 table 2 the transition probability matrix of the second order markov chain a c g t aa 0.1 + alpha 1 0.2 - alpha 1 0.3 + alpha 2 0.4 - alpha 2 ac 0.2 + alpha 1 0.3 - alpha 1 0.4 + alpha 2 0.1 - alpha 2 ag 0.3 + alpha 1 0.4 - alpha 1 0.1 + alpha 2 0.2 - alpha 2 at 0.4 + alpha 1 0.1 - alpha 1 0.2 + alpha 2 0.3 - alpha 2 ca 0.1 + beta 1 0.2 - beta 1 0.3 + beta 2 0.4 - beta 2 cc 0.2 + beta 1 0.3 - beta 1 0.4 + beta 2 0.1 - beta 2 cg 0.3 + beta 1 0.4 - beta 1 0.1 + beta 2 0.2 - beta 2 ct 0.4 + beta 1 0.1 - beta 1 0.2 + beta 2 0.3 - beta 2 ga 0.1 + gamma 1 0.2 - gamma 1 0.3 + gamma 2 0.4 - gamma 2 gc 0.2 + gamma 1 0.3 - gamma 1 0.4 + gamma 2 0.1 - gamma 2 gg 0.3 + gamma 1 0.4 - gamma 1 0.1 + gamma 2 0.2 - gamma 2 gt 0.4 + gamma 1 0.1 - gamma 1 0.2 + gamma 2 0.3 - gamma 2 ta 0.1 + delta 1 0.2 - delta 1 0.3 + delta 2 0.4 - delta 2 tc 0.2 + delta 1 0.3 - delta 1 0.4 + delta 2 0.1 - delta 2 tg 0.3 + delta 1 0.4 - delta 1 0.1 + delta 2 0.2 - delta 2 tt 0.4 + delta 1 0.1 - delta 1 0.2 + delta 2 0.3 - delta 2 the parameters alpha i,beta i,gamma i,delta i , i = 1,2 , in table 2 control the transition matrix of the second order mc. note that if alpha i = beta i = gamma i = delta i , i = 1,2 , the mc will become a first order mc. under the null hypothesis , sequences a 1 and a 2 follow the same markov model .
so we set the transition matrices for both a 1 and a 2 to be table 1 .
under the alternative hypothesis , the two sequences are different and we set the transition matrix of sequence a 1 to be from table 1 and the transition matrix of sequence a 2 to be from table 2 .
we set the parameters of table 2 to be ( 1 ) alpha i = beta i = gamma i = delta i = 0.05 , i = 1,2 , and ( 2 ) alpha 1 = alpha 2 = 0.05,beta 1 = beta 2 = - 0.05,gamma 1 = gamma 2 = 0.03,delta 1 = delta 2 = - 0.03 .
the former scenario corresponds to the situation that sequences a 1 and a 2 have different orders and the latter scenario corresponds to the situation that they both have first order but different transition matrices .
we then calculated the dissimilarity measure between sequence a 1 and a 2 using the chi 2 - statistic in eq .
( 4 ) .
we repeated the above procedures 2000 times to obtain an approximate distribution of s k under the null hypothesis .
we sorted the value of s k in ascending order and took the 95 % percentile as a threshold .
under the alternative hypothesis , the power is approximated by the fraction of times that s k is above the threshold .
figure 1 shows the relationship between the word size k and the power of s k for long sequences of different lengths .
it can be seen from the figure that the power of s k is highest when the word length is k optimal = max { r 1,r 2 }+ 1 .
when the word length is less than the optimal value , the power of s k can be significantly lower .
on the other hand , when the word length is slightly higher than the optimal word length , the power of s k is still close to the optimal power .
however , when the word length is too large , the power of s k can be much lower. fig. 1 relationship between the word length k and the power .
the transition matrix of sequence a 1 is from table 1 and the transition matrix of sequence a 2 is from table 2 with the parameters being ( a ) alpha i = beta i = gamma i = delta i = 0.05 , i = 1,2 for the first order mc and ( b ) alpha 1 = alpha 2 = 0.05 , beta 1 = beta 2 = - 0.05,gamma 1 = gamma 2 = 0.03,delta 1 = delta 2 = - 0.03 for the second order mc given long sequences , the orders of the mcs are usually not known and have to be estimated from the data .
we then studied how the power of s k changes when the estimated orders of the sequences are used compared to the power when the true orders of the sequences are known .
let \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { r }_{ 1 }$\ end { document } r ^ 1 and \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { r }_{ 2 }$\ end { document } r ^ 2 be the estimated orders of sequences a 1 and a 2 , respectively .
we compared the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{\ hat { k }}$\ end { document } sk ^ where \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { k } = \ max \ left \{ \ hat { r }_{ 1 } , \ hat { r }_{ 2 } \ right \} + 1 $\ end { document } k ^= maxr ^ 1,r ^ 2 + 1 with that of s k - optimal where k - optimal = max { r 1,r 2 }+ 1 .
the power loss is defined as the difference between the power of s k - optimal and that of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{\ hat { k }}$\ end { document } sk ^ .
when both sequences are of first order , there was no power loss in our simulations .
figure 2 shows the power loss using different methods to estimate the orders of the sequences described in eqs .
( 6 ) to ( 11 ) when the first sequence is of first order and the second sequence is of second order .
there are significant differences among the various estimators when the sequence length is below 20 kbps .
the power loss is minimal based on r aic , r bic , and r p for all three sequence lengths from 10 to 30 kbps , indicating their good performance in estimating the true markov order of the sequence .
when the sequence length is long , e.g 30kpbs , the power loss is minimal for all the estimators across the sequence lengths simulated. fig. 2 the power loss of the chi 2 - statistic based on the estimated orders of the long sequences .
a first order and a second order markov long sequences are used optimal word length for \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr for the comparison of two markov sequences with ngs data the distribution of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr was not known previously .
in this paper , we have the following theorem whose proof is given in the additional file 1 .
theorem 2 consider two markov sequences with the same length l and markov orders of r 1 and r 2 , respectively .
suppose that they are sequenced using ngs with m reads of length kappa for each sequence .
let \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr be defined as in eqs .
( 12 ) and ( 13 ) .
suppose that each sequence can be divided into ( not necessarily contiguous ) regions with constant coverage r i for the i - th region , so that every base is covered exactly r i times .
let l is be the length of the i - th region in the short read data for the s - th sequence and \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }${\ lim }_{ l \ rightarrow \ infty } l _{ is }/ l = f _{ i },~ s = 1,2 $\ end { document } liml - - > infinitylis / l = fi,s = 1,2 .
then under the null hypothesis that the two sequences follow the same markov chain , as sequence length l becomes large , \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }/ d $\ end { document } skr / d is approximately chi 2 - distributed with degrees of freedom df k =( c - 1 ) c k - 1 , where c is the alphabet size and 14 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document } $$ d =\ frac {\ sum _{ i } r ^{ 2 }_{ i } f _{ i }}{\ sum _{ j } r _{ j } f _{ j }} .
$$ \ end { document } d = sumiri2fisumjrjfj .
in particular , under the lander - waterman model , the reads are randomly sampled from the long sequence so that the ngs reads follow a poisson process with rate lambda = m kappa / l [ 29 ] , for r i = i , f i = lambda i exp ( - lambda )/ i ! , d = 1 + lambda .
if we use \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr to test whether the two sequences follow the same mc , under the alternative hypothesis , the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr is the highest when k = max { r 1,r 2 }+ 1 .
to illustrate the first part of theorem 2 , we simulated the distribution of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr under the null hypothesis .
we assumed that both sequences are of order 1 with the transition probability matrix from table 1 .
first , we generated mcs with length of l = 10 and 20 kbps , respectively .
the simulations of long sequences were the same as in " optimal word length for the comparison of markov sequences using the chi2 - statistic " subsection .
second , we simulated ngs reads by sampling a varying number of reads from each sequence .
the sampling of the reads was simulated as in [ 26,30 ] .
the length of the reads was assumed to be a constant kappa = 200 bps and the number of reads m = 100 and 200 bps , respectively .
the coverage of reads is calculated as lambda = m kappa / l. two types of read distributions were simulated : ( a ) homogeneous sampling that the reads were sampled uniformly along the long sequence [ 29 ] , and ( b ) heterogeneous sampling as in [ 31 ] .
in heterogeneous sampling , we evenly divided the long genome sequences into 100 blocks .
for each block , we sampled a random number independently from the gamma distribution gamma ( 1,20 ) .
the sampling probability for each position in the block is proportional to the chosen number .
sequencing errors are present in ngs data .
in order to see the effect of sequencing errors on the distribution of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr , we simulated sequencing errors such that each base was changed to other three bases with equal probability 0.005 .
once the reads are generated , we then calculated \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr between two ngs read data sets .
in our simulation study , we fixed k = 3 and the simulation process was repeated 2000 times for each combination of sequence length and number of reads ( l,m ) to obtain the approximate distribution of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ 3 }/ d $\ end { document } s3r / d , where d is given in eq .
( 14 ) .
figure 3 shows the q - q ( quantile - quantile ) plots of the 2000 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ 3 }/ d $\ end { document } s3r / d scores v.s .
2000 scores sampled from a \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ chi ^{ 2 }_{ 48 }$\ end { document } chi482 distribution , where the subscript 48 indicates the degrees of freedom of the chi 2 distribution .
the constant d is 1 + lambda where lambda denotes the coverage for homogeneous sampling ; and d is calculated from eq .
( 14 ) for heterogeneous sampling .
it can be seen from the figure that the q - q plots center around the line y = x for both homogeneous and heterogeneous sampling without sequencing errors .
these observations are consistent with part 1 of the theorem 2 .
however , when sequence errors are present , the distribution of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ 3 }/ d $\ end { document } s3r / d deviates slightly from \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ chi ^{ 2 }_{ 48 }$\ end { document } chi482. fig. 3 q - q plots of the 2000 \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ 3 }/ d $\ end { document } s3r / d scores v.s .
2000 scores sampled from a \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ chi ^{ 2 }_{ 48 }$\ end { document } chi482 distribution .
the length of sequences l is 20kpbs and the number of reads m is 200 .
a homogeneous sampling without errors , b homogeneous sampling with errors , c heterogeneous sampling without errors , and d heterogeneous sampling with errors we next studied how the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr changes with word length , sequence length , and sequencing errors .
here we show the results for the scenario that one sequence has first order and the other has second order .
the results for the scenario that both sequences are of first order are given in the additional file 1 .
the type i error was set at 0.05 .
figure 4 shows the relationship between the word length k and the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr using ngs short reads for different sampling of the reads and with / without sequencing errors .
several conclusions can be derived .
first , the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr is the highest when the word length k = max { r 1,r 2 }+ 1 .
this is consistent with the result with long sequences .
second , sequencing errors can decrease the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr .
however , with the range of sequencing error rates of current technologies , the decrease in power is minimal .
third , the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr based on heterogeneous sampling of the reads is lower than that based on homogeneous sampling of the reads .
fourth , the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s ^{ r }_{ k }$\ end { document } skr increases with both sequence length l and number of reads m as expected. fig. 4 the relationship between the word length k and the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr based on ngs reads .
the transition matrix of sequence a 1 is from table 1 and the transition matrix of a 2 is from table 2 .
the parameters of table 2 are alpha 1 = alpha 2 = 0.05,beta 1 = beta 2 = - 0.05,gamma 1 = gamma 2 = 0.03,delta 1 = delta 2 = - 0.03 .
a homogeneous sampling without errors , b homogeneous sampling with errors , c heterogeneous sampling without errors , and d heterogeneous sampling with errors we then studied the effect on the power of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr using the estimated orders of the markov sequences with ngs reads .
we used a similar approach as in " optimal word length for the comparison of markov sequences using the chi2 - statistic " subsection to study this problem except that we change long sequences to ngs reads .
figure 5 shows the results .
it can be seen that the power loss is significant except when r p was used to estimate the order of the sequences .
in all the simulated scenarios , the power loss is very small when r p is used to estimate the orders of markov sequences .
this result is consistent with the case of long sequences where r p also performs the best. fig. 5 the power loss of \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{ k }^{ r }$\ end { document } skr based on different methods for estimating the order of markov sequences based on ngs short reads .
panels are the same as in fig. 4. a homogeneous sampling without errors , b homogeneous sampling with errors , c heterogeneous sampling without errors , and d heterogeneous sampling with errors applications to real data searching for homologs of the human protein hslipas we used s k to analyze the relationship of 40 sequences chosen from mammals , invertebrates , viruses , plants , etc .
as in [ 32,33 ] .
we used hslipas human lipoprotein lipase ( lpl ) of length 1612 bps as the query sequence and searched for similar sequences from a library set containing 39 sequences with length from 322 to 14,121 bps .
the relationships among all the 40 sequences are well understood .
among the 39 library sequences , 20 sequences are from the primate division of genbank , classified as being related to hslipas , and 19 sequences that are from the divisions other than the primate division of genbank , classified as being not related .
wu et al .
[ 32 ] estimated the orders of the 40 sequences using schwarz information criterion ( sic ) [ 34 ] and found that 13 of them follow independent identically distributed ( i.i.d ) model ( order = 0 ) and 27 of them follow a first order mc. we also used bic and found the same results as sic .
as in wu et al .
[ 32 ] , we used selectivity and sensitivity to quantify the performance of the measure s k for different values of k. first , we calculated the dissimilarity between hslipas and each of the 39 sequences using s k and then ranked the 39 sequences in ascending order according to the values of s k. the sequence closest to hslipas is ranked as sequence 1 , the sequence with the next shortest distance as sequence 2 , etc .
sensitivity is defined as the number of hslipas - related sequences found among the first 20 ( 1 - 20 ) library sequences .
selectivity is measured in terms of consecutive correct classifications [ 35 ] , that is , starting from sequence 1 , the total number of sequences are counted until the first non - hslipas - related library sequence occurs .
thus , selectivity and sensitivity are scores from 0 to 20 and higher score means better performance on the real data set .
table 3 shows the sensitivity and selectivity of s k for different values of k from 1 to 6 .
it can be seen from table 3 that k = 2 yields the best result for both selectivity and sensitivity .
since about two thirds of the sequences have estimated order 1 and one third of the sequences have estimated order 0 , the results are consistent with our conclusion .
table 3 the selectivity and sensitivity of s k for different word length k based on the comparison of hslipas with 39 library sequences word length k 1 2 3 4 5 6 selectivity 7 11 10 7 3 1 sensitivity 13 17 16 13 12 9 comparison of crm sequences in four mouse tissues we also used s k to analyze cis - regulatory module ( crm ) sequences in four tissues from developing mouse embryo [ 36 - 38 ] as in song et al .
[ 4 ] .
the four tissues we used are forebrain , heart , limb and midbrain , with the average sequence lengths to be 711 , 688 , 657 , and 847 bps , respectively .
for each tissue , we randomly chose 500 sequences from the crm dataset to form the positive dataset .
for each sequence in the positive dataset , we randomly selected a fragment from the mouse genome with the same length , ensuring a maximum of 30 % repetitive sequences to form the negative dataset .
thus , we have a negative dataset containing another set of 500 sequences .
we calculated the pairwise dissimilarity of sequences within the positive and also the negative dataset using the s k statistic with word length from 1 - 7 .
then we merged the pairwise dissimilarity from the positive and negative datasets together .
sequences within the positive dataset should be closer than sequences within the negative dataset because the positive sequences should share some common crms .
therefore , we ranked the pairwise dissimilarity in ascending order and then predicted sequence pairs with distance smaller than a threshold as from the positive sequence pairs and otherwise we predicted them as coming from the negative pairs .
for each threshold , we calculated the false positive rate and the true positive rate .
thus , by changing the threshold , we plotted the receiver operating characteristic ( roc ) curve and calculated the area under the curve ( auc ) .
for each tissue and each word length k , we repeated the above procedures 30 times .
we used bic to estimate the mc orders of the sequences .
the estimated orders of positive sequences for all four tissues are given in the additional file 1 .
almost all positive sequences in the positive dataset have estimated orders of 0 or 1 .
the results are similar for the negative sequences ( data not shown ) .
figure 6 shows the relationship between the word length k and the auc values in all four tissues using boxplot for the 30 replicates .
it can be seen from the figure that the auc values using word length 1 - 3 are much higher than that using word length 4 - 7 .
the auc values when k = 1 are slightly higher than that when k = 2 and k = 3 .
however , the differences are relatively small .
the results are consistent in all four tissues .
these results show that when the word length is close to the optimal word length based on our theoretical results , the auc is generally higher than that when the word length is far away from the optimal word length based on our theoretical results. fig. 6 boxplot of the auc values for different word lengths k. for each k and each tissue , 30 auc values based on 30 repeated experiments are shown .
the subplots show results based on different tissues : a forebrain , b heart , c limb , and d midbrain discussion in this paper , we investigated only the chi 2 - statistic for alignment - free genome comparison and the optimality criterion is to maximize the power of the chi 2 - statistic under the alternative hypothesis .
many other alignment - free genome comparison statistics are available as reviewed in [ 4,5 ] .
the optimal word length we derived in this study may not be applicable to other statistics .
we assumed that the sequences of interest are markov chains .
real molecular sequences do not exactly follow markov chains and the sequences are also highly related .
the relationship between the true evolution distance between the sequences and the pairwise chi 2 - dissimilarity using the optimal word length needs to be further investigated .
these are the topics for future studies .
conclusions in this paper , we study the optimal word length when comparing two markov sequences using word count statistics , in particular , the likelihood ratio statistic and the corresponding chi 2 - statistic defined in eq .
( 4 ) .
we showed theoretically and by simulations that the optimal word length is k = max { r 1,r 2 }+ 1 .
when the orders of the sequences are not known and have to be estimated from the sequence data , we showed that the estimator r p defined in eq .
( 10 ) and the estimator r aic defined in eq .
( 6 ) have the best performance , followed by r bic defined in eq .
( 7 ) based on long sequences .
we then extended these studies to ngs read data and found that the conclusions about the optimal word length continue to hold .
it was also shown that if we use r p defined in eq .
( 10 ) to estimate the orders of the markov sequences based on ngs reads \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { r }_{ p1 }$\ end { document } r ^ p1 and \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { r }_{ p2 }$\ end { document } r ^ p2 , respectively , and then compare the sequences using \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$ s _{\ hat { k } - \ text { optimal }}$\ end { document } sk ^ - optimal , with \ documentclass [ 12pt ]{ minimal } \ usepackage { amsmath } \ usepackage { wasysym } \ usepackage { amsfonts } \ usepackage { amssymb } \ usepackage { amsbsy } \ usepackage { mathrsfs } \ usepackage { upgreek } \ setlength {\ oddsidemargin }{ - 69pt } \ begin { document }$\ hat { k } - \ text { optimal } = \ max \{ \ hat { r }_{ p1 } , \ hat { r }_{ p2 } \}+ 1 $\ end { document } k ^ - optimal = max { r ^ p1,r ^ p2 }+ 1 , the power loss is minimal .
these conclusions are not significantly changed by sequencing errors .
therefore , our studies provide guidelines on the optimal choice of word length for alignment - free genome comparison using the chi 2 - statistic .
additional file additional file 1 supplementary materials .
proofs of theorem 1 and 2 , simulation results for the comparison of two first order markov sequences based on ngs reads and estimated orders of positive sequences in four mouse tissues .
( pdf 274 kb ) electronic supplementary material the online version of this article ( doi : 10.1186 / s12864 - 017 - 4020 - z ) contains supplementary material , which is available to authorized users .
acknowledgements we would like to thank prof. minping qian at peking university ( pku ) for suggestions on the proof of theorem 1 , and yang y lu at usc for providing the software and suggestions to improve the paper .
funding this research is partially supported by us nsf dms - 1518001 and oce 1136818 , simons institute for the theory of computing at uc berkeley , and fudan university , china .
the publication costs of this paper were provided by fudan university , shanghai , china .
availability of data and materials data of the first real data application can be downloaded from [ 33 ] .
data of the second real data application can be downloaded from [ 37 ] .
about this supplement this article has been published as part of bmc genomics volume 18 supplement 6 , 2017 : selected articles from the international conference on intelligent biology and medicine ( icibm ) 2016 : genomics .
the full contents of the supplement are available online at https :// bmcgenomics.biomedcentral.com / articles / supplements / volume - 18 - supplement - 6 .
authors' contributions fs and msw conceived the study , designed the framework of the paper and finalized the manuscript .
xb did the simulation studies , proved the theorems , and wrote the manuscript .
kt and jr participated in the real data analysis .
all authors read and approved the final manuscript .
ethics approval and consent to participate not applicable .
consent for publication not applicable .
competing interests the authors declare that they have no competing interests .
publisher 's note springer nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations .
references 1 smith tf waterman ms identification of common molecular subsequences j mol biol 1981 147 1 195 7 10.1016 / 0022 - 2836 ( 81 ) 90087 - 5 7265238 2 altschul sf gish w miller w myers ew lipman dj basic local alignment search tool j mol biol 1990 215 3 403 10 10.1016 / s0022 - 2836 ( 05 ) 80360 - 2 2231712 3 kent wj blat , the blast - like alignment tool genome res 2002 12 4 656 64 10.1101 / gr.229202 11932250 4 song k ren j reinert g deng m waterman ms sun f new developments of alignment - free sequence comparison : measures , statistics and next - generation sequencing brief bioinform 2014 15 3 343 53 10.1093 / bib / bbt067 24064230 5 vinga s almeida j alignment - free sequence comparison - a review bioinformatics 2003 19 4 513 23 10.1093 / bioinformatics / btg005 12611807 6 qi j luo h hao b cvtree : a phylogenetic tree reconstruction tool based on whole genomes nucleic acids res 2004 32 web server issue 45 10.1093 / nar / gkh362 14704342 7 behnam e waterman ms smith ad a geometric interpretation for local alignment - free sequence comparison j comput biol 2013 20 7 471 85 10.1089 / cmb.2012.0280 23829649 8 torney dc burks c davison d sirotkin km computation of d2 : a measure of sequence dissimilarity comput dna 1990 7 109 25 9 reinert g chew d sun fz waterman ms alignment - free sequence comparison ( i ) : statistics and power j comput biol 2009 16 12 1615 34 10.1089 / cmb.2009.0198 20001252 10 karlin s burge c dinucleotide relative abundance extremes : a genomic signature trends genet 1995 11 7 283 90 10.1016 / s0168 - 9525 ( 00 ) 89076 - 9 7482779 11 blaisdell be a measure of the similarity of sets of sequences not requiring sequence alignment proc natl acad sci usa 1986 83 14 5155 9 10.1073 / pnas.83.14.5155 3460087 12 blaisdell be markov chain analysis finds a significant influence of neighboring bases on the occurrence of a base in eucaryotic nuclear dna sequences both protein - coding and noncoding j mol evol 1985 21 3 278 88 10.1007 / bf02102360 13 sims ge jun sr wu ga kim sh alignment - free genome comparison with feature frequency profiles ( ffp ) and optimal resolutions proc natl acad sci usa 2009 106 8 2677 82 10.1073 / pnas.0813249106 19188606 14 foret s kantorovitz mr burden cj asymptotic behaviour and optimal word size for exact and approximate word matches between random sequences bmc bioinforma 2006 7 5 1 15 wu tj huang yh li la optimal word sizes for dissimilarity measures and estimation of the degree of dissimilarity between dna sequences bioinformatics 2005 21 22 4125 32 10.1093 / bioinformatics / bti658 16144805 16 pevzner pa borodovsky my mironov aa linguistics of nucleotide sequences i : the significance of deviations from mean statistical characteristics and prediction of the frequencies of occurrence of words j biomol struct dyn 1989 6 5 1013 26 10.1080 / 07391102.1989.10506528 2531596 17 hong j prediction of oligonucleotide frequencies based upon dinucleotide frequencies obtained from the nearest neighbor analysis nucleic acids res 1990 18 6 1625 8 10.1093 / nar / 18.6.1625 2158083 18 arnold j cuticchia aj newsome da jennings ww ivarie r mono - through hexanucleotide composition of the sense strand of yeast dna : a markov chain analysis nucleic acids res 1988 16 14 7145 58 10.1093 / nar / 16.14.7145 3043378 19 avery pj the analysis of intron data and their use in the detection of short signals j mol evol 1987 26 4 335 40 10.1007 / bf02101152 3131534 20 narlikar l mehta n galande s arjunwadkar m one size does not fit all : on how markov model order dictates performance of genomic sequence analyses nucleic acids res 2013 41 3 1416 24 10.1093 / nar / gks1285 23267010 21 anderson tw goodman la statistical inference about markov chains ann math stat 1957 28 4 89 110 10.1214 / aoms / 1177707039 22 billingsley p statistical methods in markov chains ann math stat 1961 32 1 12 40 10.1214 / aoms / 1177705136 23 tong h determination of the order of a markov chain by akaike 's information criterion j appl probab 1975 12 488 97 10.1017 / s0021900200048294 24 katz rw on some criteria for estimating the order of a markov chain technometrics 1981 23 3 243 9 10.2307 / 1267787 25 peres y , shields p. two new markov order estimators .
arxiv preprint math / 0506080 .
2005. 26 ren j song k deng m reinert g cannon ch sun f inference of markovian properties of molecular sequences from ngs data and applications to comparative genomics bioinformatics 2016 32 7 993 1000 10.1093 / bioinformatics / btv395 26130573 27 hoel pg a test for markov chains biometrika 1954 41 3 / 4 430 3 10.2307 / 2332723 28 billingsley p statistical inference for markov processes , vol 2 1961 chicago university of chicago press 29 lander es waterman ms genomic mapping by fingerprinting random clones : a mathematical analysis genomics 1988 2 3 231 9 10.1016 / 0888 - 7543 ( 88 ) 90007 - 9 3294162 30 song k ren j zhai z liu x deng m sun f alignment - free sequence comparison based on next - generation sequencing reads j comput biol 2013 20 2 64 79 10.1089 / cmb.2012.0228 23383994 31 zhang zd rozowsky j snyder m chang j gerstein m modeling chip sequencing in silico with applications plos comput biol 2008 4 8 1000158 10.1371 / journal.pcbi.1000158 32 wu t hsieh y li l statistical measures of dna sequence dissimilarity under markov chain models of base composition biometrics 2001 57 441 8 10.1111 / j.0006 - 341x.2001.00441.x 11414568 33 hide w burke j davison d biological evaluation of d2 , an algorithm for high performance sequence comparison j comput biol 1994 1 199 215 10.1089 / cmb.1994.1.199 8790465 34 schwarz g estimating the dimension of a model annals stat 1978 6 461 4 10.1214 / aos / 1176344136 35 wu t burke jp davison db a measure of dna sequence dissimilarity based on mahalanobis distance between frequencies of words biometrics 1997 53 1431 9 10.2307 / 2533509 9423258 36 goke j schulz mh lasserre j vingron m estimation of pairwise sequence similarity of mammalian enhancers with word neighbourhood counts bioinformatics 2012 28 5 656 63 10.1093 / bioinformatics / bts028 22247280 37 blow mj mcculley dj li z zhang t akiyama ja holt a plajzer - frick i shoukry m wright c chen f chip - seq identification of weakly conserved heart enhancers nat genet 2010 42 9 806 10 10.1038 / ng.650 20729851 38 visel a blow m li z chip - seq accurately predicts tissue - specific activity of enhancers nature 2009 457 7231 854 8 10.1038 / nature07730 19212405