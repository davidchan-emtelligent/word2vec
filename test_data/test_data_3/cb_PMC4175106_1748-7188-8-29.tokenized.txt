algorithms mol biol algorithms mol biol algorithms for molecular biology : amb 1748 - 7188 biomed central 24180434 4175106 1748 - 7188 - 8 - 29 10.1186 / 1748 - 7188 - 8 - 29 software article accelerating calculations of rna secondary structure partition functions using gpus stern harry a 1 hstern2 @ ur.rochester.edu mathews david h 2 david _ mathews @ urmc.rochester.edu 1 center for integrated research computing , taylor hall , university of rochester , rochester , ny , 14627 , usa 2 department of biochemistry & biophysics and center for rna biology , university of rochester medical center , 601 , elmwood avenue box 712 , rochester , ny , 14642 , usa 2013 1 11 2013 8 29 29 31 1 2013 14 10 2013 copyright ( c ) 2013 stern and mathews ; licensee biomed central ltd .
2013 stern and mathews ; licensee biomed central ltd.this is an open access article distributed under the terms of the creative commons attribution license ( http :// creativecommons.org / licenses / by / 2.0 ) , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .
background rna performs many diverse functions in the cell in addition to its role as a messenger of genetic information .
these functions depend on its ability to fold to a unique three - dimensional structure determined by the sequence .
the conformation of rna is in part determined by its secondary structure , or the particular set of contacts between pairs of complementary bases .
prediction of the secondary structure of rna from its sequence is therefore of great interest , but can be computationally expensive .
in this work we accelerate computations of base - pair probababilities using parallel graphics processing units ( gpus ) .
results calculation of the probabilities of base pairs in rna secondary structures using nearest - neighbor standard free energy change parameters has been implemented using cuda to run on hardware with multiprocessor gpus .
a modified set of recursions was introduced , which reduces memory usage by about 25 % .
gpus are fastest in single precision , and for some hardware , restricted to single precision .
this may introduce significant roundoff error .
however , deviations in base - pair probabilities calculated using single precision were found to be negligible compared to those resulting from shifting the nearest - neighbor parameters by a random amount of magnitude similar to their experimental uncertainties .
for large sequences running on our particular hardware , the gpu implementation reduces execution time by a factor of close to 60 compared with an optimized serial implementation , and by a factor of 116 compared with the original code .
conclusions using gpus can greatly accelerate computation of rna secondary structure partition functions , allowing calculation of base - pair probabilities for large sequences in a reasonable amount of time , with a negligible compromise in accuracy due to working in single precision .
the source code is integrated into the rnastructure software package and available for download at http :// rna.urmc.rochester.edu .
rna secondary structure partition function graphical processing unit cuda background rna performs many diverse functions in the cell in addition to its role as a messenger of genetic information .
it can form enzymes , for example for cleavage of itself or of other rna , or to create peptide bonds as a fundamental constituent of the ribosome [ 1 ] .
it can act as a signalling molecule for regulation of gene expression , for protein export , or for guiding post - translational modifications [ 2 - 5 ] .
as for proteins , rna function depends on its folding to a well - defined three - dimensional shape .
in contrast to proteins , the folding of rna is hierarchical [ 6 ] .
secondary structure , or the particular set of contacts between pairs of complementary bases mediated by hydrogen bonding and stacking of bases , provides a significant amount of information .
this can be helpful in predicting function or accessibility to ligands [ 7 - 10 ] .
computational prediction of the secondary structure of rna from its sequence is therefore of great interest .
the most widely - used automated prediction methods attempt to estimate the thermodynamic stability of rna , using empirical parameters determined from experiments on oligonucleotides [ 11,12 ] .
cuda is a programming interface developed by the company nvidia to facilitate general - purpose , parallel high - performance computing on multiprocessor graphics processing units ( gpus ) [ 13 ] .
in recent years , many scientific computing applications have been implemented on gpus using cuda , in many cases yielding speed - ups of several orders of magnitude [ 14,15 ] .
however , to our knowledge , only a handful of publications have appeared describing gpu implementations of codes for rna secondary structure prediction .
rizk and lavenier described a cuda implementation of structure prediction by free energy minimization [ 16 ] .
their work was limited to relatively short sequences ( up to 120 bases ) and a simplified energy model that neglects coaxial stacking .
the gpu implementation was faster than the serial implementation by a factor of 10 and 17 depending on the particular hardware .
more recently , lei et al .
[ 17 ] also reported a parallelized implementation of free energy minimization using cuda .
they used only a coarse - grained parallelization scheme where the minimum - free - energy structures for subsequences of a given length are calculated in parallel , but the search over structures for each subsequence is done serially .
their work was also limited to relatively short sequences ( up to 221 bases ) .
they reported speedups of up to a factor of 16 .
it should be noted that these parallelized implementations neither use the latest thermodynamic parameters for loops [ 18 ] , nor include coaxial stacking interactions [ 19 ] .
in addition , recent work demonstrates that calculations of base - pairing probabilities calculated with partition functions can provide additional useful information [ 20 ] .
structures composed of highly probable pairs are more accurate than lowest free energy structures [ 20,21 ] .
the base pair probabilities provide confidence intervals for prediction of individual pairs .
base pairing probabilities can also be used to predict pseudoknots [ 22 ] .
we have additionally extended this work to predictions using multiple , homologous sequences , where the same principles hold true [ 23 - 26 ] .
in this paper , we present the calculation of base - pair probabilities for 44 sequences containing up to 10,000 bases , using an optimized and parallelized version of the " partition " code in the rnastructure package [ 27 ] .
our test set contained both random sequences of varying lengths ( up to 10,000 bases ) and actual sequences of biological importance ( see table 1 ) , the longest being the hiv - 1 nl43 genome ( genbank : af324493 ) containing 9709 bases .
table 1 biological rna sequences examined * sequence # bases reference trna rq2640 75 [ 28 ] trna rd0500 76 [ 28 ] trna ra7680 76 [ 28 ] trna rd0260 77 [ 28 ] trna rr1664 77 [ 28 ] candida albicans 5s rrna 114 [ 29 ] escherichia coli 5s rrna 120 [ 30 ] p546 folding domain of tetrahymenathermophilia group i intron 155 [ 31 ] bacillus stearothermophilus srp rna 268 [ 32 ] 3 ' utr of bombyx mori r2 element with flanking vector sequence 300 [ 33 ] tetrahymena thermophilia group i intron 433 [ 30 ] saccharomyces cerevisiae a5 group ii intron 632 [ 34 ] escherichia coli small subunit rrna 1542 [ 30 ] escherichia coli large subunit rrna 2904 [ 29 ] human icam - 1 mrna 2986 [ 35 ] hiv - 1 nl43 genome ( genbank : af324493 ) 9709 [ 36 ] * 28 random sequences of length 10 - 10,000 were also examined .
we employed a sophisticated and accurate energy calculation that includes coaxial stacking [ 19 ] .
before attempting a parallel implementation , we first wrote an optimized serial version of the original code ( the " partition " program in rnastructure ) , implementing only a subset of its functionality , while improving efficiency and reducing memory usage .
subsequently , we parallelized the optimized code for gpu hardware , using cuda .
here we made use of a fine - grained parallelization scheme , in which the calculation of the restricted partition function for each subsequence of a given length is parallelized , as well as the calculation of the restricted partition function for each subsequence .
we found that this fine - grained parallelization resulted in greater speedups than a simpler coarse - grained - only parallelization ( up to factors of ~ 60 compared to the optimized serial version and ~ 116 compared to the original code ) .
implementation calculating base pair probabilities the probability pi,j of a canonical pair between bases i and j related to the standard free energy change deltagi,j0 of the restricted ensemble of structures containing the pair , and the standard free energy change deltag0 of the unrestricted ensemble of all possible structures , both relative to the state in which all bases are unpaired : ( 1 ) pi,j = wdeltagi,j0wdeltag0 where ( 2 ) w ( g )= exp - g / rt is the boltzmann weight corresponding to standard free energy change g at temperature t. the standard free energy changes deltagi,j0 and deltag0 are estimated using the turner nearest - neighbor rules [ 11,18,37 ] , and pseudoknots are excluded .
in that case , deltagi,j0 depends on two independent contributions , one for the interior fragment containing the pair i,j and bases in between ( but excluding bases from the 5 ' end to i - 1 and from j + 1 to the 3 ' end ) , and one for the exterior fragment containing the pair and bases from the two ends ( but excluding bases from i + 1 to j - 1 ) .
we define vi,j to be the relative standard free energy change for the interior fragment in the case that i < j and for the exterior fragment otherwise , following the convention used in the mfold prediction software [ 38 ] .
in that case , ( 3 ) deltagi,j0 = - rtlogexp - vi,j / rt + exp - vj,i / rt or more succinctly ( 4 ) wdeltagi,j0 = wvi,j + wvj,i the standard free energy changes vi,j are calculated using the following set of recursions : ( 5 ) wvi,j = qi,jhairpin + qi,jstack + qi,jinternal + qi,jmultibranchfori < jqi,jexterior + qi,jstack + qi,jinternal + qi,jmultibranchfori > j where ( 6 ) qi,jhairpin = wdeltagi,jhairpin ( 7 ) qi,jstack = wvi + 1,j - 1 + deltagi,j,i + 1,j - 1stack ( 8 ) qi,jinternal = sumi < i '< j '< jwvi ' , j '+ deltagi,j,i ' , j'internal ( 9 ) qi,jmultibranch = wwi + 1,j - 1mb + a + c + wwi + 2,j - 1mb + deltagi,j,i + 13'dangle + a + b + c + wwi + 1,j - 2mb + deltagi,j,j - 15'dangle + a + b + c + wwi + 2,j - 2mb + deltagi,j,i + 1,j - 1terminalmismatch + a + 2b + c + sumi < k < jwvi + 1,k + yk + 1,j - 1 + deltagj,i,i + 1,kcoaxial flush + a + 2c + sumi < k < jwvi + 2,k + yk + 2,j - 1 + deltagj,i,i + 2,kcoaxial mismatch ( 2 )+ a + 2b + 2c + sumi < k < jwvi + 2,k + yk + 1,j - 2 + deltagj,i,i + 2,kcoaxial mismatch ( 1 )+ a + 2b + 2c + sumi < k < jwvk,j - 1 + yi + 1,k - 1 + deltagk,j - 1,j,icoaxial flush + a + 2c + sumi < k < jwvk,j - 2 + yi + 1,k - 2 + deltagk,j - 2,j,icoaxial mismatch ( 1 )+ a + 2b + 2c + sumi < k < jwvk,j - 2 + yi + 2,k - 1 + deltagk,j - 2,j,icoaxial mismatch ( 2 )+ a + 2b + 2c ( 10 ) qi,jexterior = wwi + 13 '+ wj - 15 '+ wwi + 23 '+ wj - 15 '+ deltagi,j,i + 13'dangle ++ wwi + 13 '+ wj - 25 '+ deltagi,j,j - 15'dangle ++ wwi + 23 '+ wj - 25 '+ deltagi,j,i + 1,j - 1terminalmismatch + sumi < k < jwvi + 1,k + wk + 13 '+ wj - 15 '+ deltagj,i,i + 1,kcoaxial flush + sumi < k < jwvi + 2,k + wk + 23 '+ wj - 15 '+ deltagj,i,i + 2,kcoaxial mismatch ( 2 )+ sumi < k < jwvi + 2,k + wk + 13 '+ wj - 25 '+ deltagj,i,i + 2,kcoaxial mismatch ( 1 )+ sumi < k < jwvk,j - 1 + wi + 13 '+ wk - 15 '+ deltagk,j - 1,j,icoaxial flush + sumi < k < jwvk,j - 2 + wi + 13 '+ wk - 25 '+ deltagk,j - 2,j,icoaxial mismatch ( 1 )+ sumi < k < jwvk,j - 2 + wi + 23 '+ wk - 15 '+ deltagk,j - 2,j,icoaxial mismatch ( 2 ) ( 11 ) wwi,jl = wwi + 1,jl + b + wvi,j + c + wvi,j - 1 + deltagj - 1,i,j3'dangle + b + c + wvi + 1,j + deltagj,i + 1,i5'dangle + b + c + wvi + 1,j - 1 + deltagj - 1,i + 1,j,iterminalmismatch + 2b + c ( 12 ) wwi,jq = wvi,j + wvi,j - 1 + deltagj - 1,i,j3'dangle + wvi + 1,j + deltagj,i + 1,i5'dangle + wvi + 1,j - 1 + deltagj - 1,i + 1,j,iterminalmismatch ( 13 ) wwi,j = wwi,j - 1 + b + wwi,jl ( 14 ) wwi,jcoax = sumi < k < jwvi,k + vk + 1,j + deltagi,k,k + 1,jcoaxial flush + 2c + sumi < k < jwvi + 1,k + vk + 2,j + deltagi + 1,k,kj + 2,jcoaxial mismatch ( 1 )+ 2b + 2c + sumi < k < jwvi,k + vk + 2,j - 1 + deltagi,k,k + 2,j - 1coaxial mismatch ( 2 )+ 2b + 2c ( 15 ) wzi,j = wwi,jcoax + wvi,j + c + wvi,j - 1 + deltagj - 1,i,j3'dangle + b + c + wvi + 1,j + deltagj,i + 1,i5'dangle + b + c + wvi + 1,j - 1 + deltagj - 1,i + 1,j,iterminalmismatch + 2b + c ( 16 ) wwi,jmbl = wwi + 1,jmbl + wwi,jcoax + sumi < k < jwzi,k + yk + 1,jl ( 17 ) wwi,jmb = wwi,j - 1mb + b + wwi,jmbl ( 18 ) wyi,j = wwi,j + wwi,jmb ( 19 ) wyi,jl = wwi,jl + wwi,jmbl ( 20 ) wwi5 '= wwi - 15 '+ sumj < iwwj - 15 '+ wj,iq ( 21 ) wwi3 '= wwi + 13 '+ sumj > iwwj + 13 '+ wi,jq these recursions are slightly different from - - but equivalent to - - those presented in reference [ 20 ] and used in the previous code .
it should be noted that there was an error in equation 15 of reference [ 20 ] : in the second line , wmbl ( k + 1,j ) should be replaced by [ wmbl ( k + 1,j ) + wl ( k + 1,j )] .
the quantities v , w , wmb , wl , wcoax , w5 ' , and w3 ' are simply - rt times the logarithms of the quantities in reference [ 20 ] .
in addition , four new arrays are introduced : 1 .
wq is the standard free energy change corresponding to the sum of terms on the right hand side of equation 11 of reference [ 20 ] not including the scaling by w5 ( k ) .
2. elements of y are - rt times the logarithm of the sum of the boltzmann weights of corresponding elements of w and wmb .
3. elements of yl are - rt times the logarithm of the sum of the boltzmann weights of corresponding elements of wl and wmbl .
4. elements of z are - rt times the logarithm of the sum of the boltzmann weights of corresponding elements of wl ( except for the term depending on the next - smallest fragment ) and wcoax .
reorganizing the recursions in this way might appear to use more memory because of the additional arrays .
in fact , the modified version requires less memory , because several of the arrays do not need to be stored in their entirety .
specifically , using the modified recursions , storage is only required for two diagonals of w , wl , and wmbl ; for five diagonals of wmb ; and for a half - triangle of wq. reducing memory usage is important as the size of the full arrays scales as o ( n2 ) and the available gpu memory on our hardware was limited to ~ 2.5 gb. the modified recursions use four full nxn arrays and one half - triangle , rather than the six full nxn arrays used in the original recursions , and therefore reduce memory usage by about 25 % .
in addition , the calculation of w5 ' and w3 ' is simplified ( compare equations 20 and 21 above with equation 11 of reference [ 20 ]) .
as in the previous work , the various deltag parameters above are from the turner nearest - neighbor rules [ 11 ] , while a,b , and c are from the following estimate of the standard free energy change for multibranch loop initiation : ( 22 ) deltag0 = a + bn + ch here n is the number of unpaired nucleotides and h is the number of branching helices [ 21 ]. by convention , the size of internal loops is limited to thirty unpaired nucleotides , so the number of terms in equation 8 and the overall computational expense scales as o ( n3 ) where n is the size of the sequence .
the largest difference in the new implementation is that logarithms of probabilities and partition functions ( i.e. , standard free energy changes ) are used rather than probabilities themselves , which is convenient when working in single precision in order to avoid overflow or underflow errors .
this requires that exponentials and logarithms are calculated at each step of the calculation where sums are performed .
this approach is a departure from the previous implementation , which used scaling factors .
having to compute logarithms and exponentials does entail some additional computational expense , but this does not appear to be exhorbitant on the gpu , because optimized intrinsic mathematical functions are used .
( i.e. , the code was compiled with the nvidia compiler using the - use _ fast _ math option ) .
the function required for the sum of two free energies a and b ( expressed in units such that rt = 1 ) is ( 23 ) f ( a,b )= - loge - a + e - b we calculated this in the following way : ( 24 ) f ( a,b )= a - log1 + ea - ba < bb - log1 + eb - aa > ba - log ( 2 ) a = b this was done for two reasons : it requires at most a single call to exp , rather than two ; and it can make use of the log1p function from the standard math library , which calculates log ( 1 + x ) accurately even for small x. this is important because often e - a and e - b will differ by several orders of magnitude , and simply adding them and then taking the logarithm can lead to significant roundoff error .
in order to determine how much additional computational overhead was imposed by the calculation of exp and log1p we performed a comparison with an artificial reference calculation , which was identical except that calls to these functions were omitted .
we found that for a 1,000 - mer , the actual gpu calculation is only ~ 20 % more expensive than this reference calculation .
for a serial calculation on the cpu , there is a larger performance hit ; the actual calculation is about a factor of two more expensive than the reference without exp or log1p .
however , it should be noted that this is not the entire story , because overall , the new optimized serial code , which uses logarithms , is still faster than the original code , which does not .
running the calculation in log space results in simplifications such as not requiring checking for overflow and not having to multiply by scaling factors , which reduces computational expense .
parallelization of the partition function calculation using cuda in the cuda programming model , overall execution of the program is still governed by the cpu .
compute - intensive portions of the program are then delegated to subroutines executed by the gpu , or kernels .
in general , the gpu has its own memory , so data must be copied to and from the gpu before and after kernel execution .
many copies of a kernel , or threads , run in parallel , each of which belongs to a block .
during kernel execution , threads belonging to the same block can share data and synchronize , whereas threads belonging to different blocks cannot .
a program can contain many kernels , which can execute either serially or in parallel [ 13 ] .
the algorithm for calculating partition functions is recursive : partition functions for larger fragments depend on those for smaller fragments .
as such , the overall calculation proceeds serially , in order of fragment size .
we used two levels of parallelization , a block level and a thread level .
calculations for all fragments of a given size may be done in parallel , with no communication .
this was implemented in cuda at the level of blocks of threads .
the partition function for a given fragment depends on sums , with the number of terms on the order of the fragment size ( e.g. , equation 9 ) .
these sums were parallelized at the level of threads within a block , since calculating a sum in parallel relies on communication between the threads .
in our experience , a greater speedup was obtained from this " inner loop " parallelization , even though it requires more communication between threads .
most likely , this is because optimal efficiency on gpu hardware is obtained when identical mathematical operations are performed in lockstep on different data [ 13 ] .
we stress that these two different levels of parallelization are not mutually exclusive and optimal performance was obtained from including both .
a separate block of threads was run for each fragment , while 256 threads were run within a block .
the number of threads per block was chosen by trial and error and was optimal for our hardware ( the simple sum reduction scheme we chose requires it to be a power of two ) .
in our code , this value is set at compile time ( but this is not required by cuda - - it could be set at run time if desired ) .
results and discussion accuracy peak floating point performance for nvidia tesla gpus are faster by a factor of two when working in single compared with working in double precision ( http :// www.nvidia.com ) , but single precision introduces greater roundoff error .
in order to examine accuracy , we calculated base - pair probabilities for the same sequences using both the parallel cuda / gpu implementation in single precision , and the serial implementation in double precision .
we also calculated probabilities in double precision using a set of nearest - neighbor parameters slightly modified by adding a random variate chosen from a gaussian distribution with mean 0 and standard deviation 0.01 kcal / mol , which is comparable to or smaller than their experimental uncertainty ( 0.1 kcal / mol for parameters describing helical stacking and 0.5 kcal / mol for parameters describing loops [ 18,37 ]) .
figure 1 shows the root - mean - square deviation ( rmsd ) between base - pair probabilities calculated using double precision and either single precision , or the modified parameters .
the rmsd of the calculation using modified parameters decreases as the size of the sequences increases ( because the fraction of pairs with very small probabilities increases ) .
in contrast , the roundoff error due to working in single precision increases as the cube of the number of bases in the sequence ( i.e. , the number of operations involved in the calculation ) .
however , it remains relatively small for sequences of up to 10,000 bases , and negligible compared with the differences resulting from the modified parameters .
our conclusion is that working in single precision does not introduce unacceptable roundoff error for rna secondary structure prediction for sequences of this size and most likely substantially larger .
figure 1 accuracy of base - pair probabilities .
root - mean - square deviation in base - pair probabilities calculated using the cuda single - precision implementation ( red plus signs ) and the serial double - precision implementation with slightly modified parameters ( green crosses ) , compared with the serial double - precision implementation using the original parameters .
we also used the calculated base pair probabilities to determine a single consensus structure for each sequences , using the probknot algorithm [ 22 ] .
in this case , working in single precision led to differences with double precision only for one sequence ( a random sequence of 6000 bases ) out of the 44 we examined , and these were very small ( only three bases out of the 6000 were matched with a different partner ) .
working with the modified parameters led to larger discrepancies although these were still fairly small ( for sequences containing more than 100 bases , at most 6 % of bases were matched with different partners ) .
this is consistent with a previous report that predictions using base pair probabilities are significantly less sensitive to errors in thermodynamic parameters than using only lowest free energy structures [ 39 ] .
computational expense we compared overall execution time for the original serial code developed in our laboratory , the optimized serial code , and the parallel cuda / gpu implementation .
calculations were performed for sequences containing from 10 to 10,000 bases , on compute nodes containing dual hex - core intel xeon 2.67 ghz cpus and dual nvidia tesla m2050 gpus , each of which contains 448 multiprocessor cores ( only a single gpu was used ) .
figure 2 shows the execution time ( from the user time reported by the unix " time " command ) of the original and optimized serial codes as well as the parallel cuda / gpu implementation .
the execution time for all codes scales as the cube of the sequence length for large sequences .
the cuda version was able to calculate base - pair probabilities for the sequence for the full hiv - 1 nl43 genome ( 9709 nucleotides ) in 27 minutes .
we note that there is a small overhead ( a few hundredths of a second ) involved in running calculations with either the original serial code or the cuda code , which is not present for the optimized serial code .
this overhead has different origins : for the original code , it is probably due to reading the parameter files from disk , while for the cuda code , it is most likely due to copying parameters and other data between the gpu and cpu .
figure 2 computational expense .
execution time in seconds for the original serial implementation ( red plus signs ) , optimized serial implementation ( green crosses ) , and parallel gpu implementation ( blue asterisks ) .
the red , green , and blue lines are the cube of the number of bases n in the sequences , multiplied by a constant chosen to best fit the corresponding execution times .
conclusions in this work , we introduced a modified set of recursions for calculating rna secondary structure partition functions and base - pairing probabilities using a dynamic programming algorithm , and implemented these in parallel using the cuda framework for multiprocessor gpus .
for large sequences , the gpu implementation reduces execution time by a factor of close to 60 compared with an optimized serial implementation , and by a factor of 116 compared with the original code .
it is clear from our work that using gpus can greatly accelerate computation of rna secondary structure partition functions , allowing calculation of base - pair probabilities for large sequences in a reasonable amount of time , with a negligible compromise in accuracy due to working in single precision .
it is expected that parallelization using cuda should be applicable to other implementations of dynamic programming algorithms [ 12 ] besides ours , and result in similar speedups .
two levels of parallelization were implemented .
calculations for all fragments of a given size were done in parallel , with no communication between threads .
this was implemented in cuda at the level of blocks of threads .
in addition , the sums contributing to the partition function for a given fragment were calculated in parallel , with communication required between threads .
these sums were parallelized at the level of thread within a block .
we found that this " inner loop " parallelization resulted in a significantly greater speedup than the " outer loop " parallelization alone .
availability and requirements * project name : partition - cuda ; part of rnastructure , version 5.5 and later * project home page : http :// rna.urmc.rochester.edu / rnastructure.html * operating system ( s ) : unix * programming languages : c and cuda * other requirements : cuda compiler , available from * http :// www.nvidia.com / object / cuda \_ home \_ new.html * license : gnu gpl * any restrictions to use by non - academics : none .
competing interests the authors declare that they have no competing interests .
authors' contributions has and dhm conceived of this work. has implemented the new partition function recursions for serial and parallel execution and performed the test calculations. has wrote the first draft of the manuscript , and dhm provided input to the final manuscript .
both authors read and approved the final manuscript .
acknowledgements this work was supported by nih grant r01gm076485 to d. h. m. and the center for integrated research computing at the university of rochester .
doudna ja cech tr the chemical repertoire of natural ribozymes nature 2002 418 222 10.1038 / 418222a 12110898 bachellerie jp cavaille j huttenhofer a the expanding snorna world biochimie 2002 84 775 10.1016 / s0300 - 9084 ( 02 ) 01402 - 5 12457565 walter p blobel g signal recognition particle contains a 7s rna essential for protein translocation across the endoplasmic reticulum nature 1982 299 691 10.1038 / 299691a0 6181418 dykxhoorn dm novina cd sharp pa killing the messenger : short rnas that silence gene expression nat rev mol cell biol 2003 4 457 12778125 wu l belasco jg let me count the ways : mechanisms of gene regulation by mirnas and sirnas mol cell 2008 29 1 10.1016 / j.molcel.2007.12.010 18206964 bustamante c tinoco i jr how rna folds j mol biol 1999 293 271 10.1006 / jmbi.1999.3001 10550208 nawrocki ep kolbe dl eddy sr infernal 1.0 : inference of rna alignments bioinformatics 2009 25 1335 10.1093 / bioinformatics / btp157 19307242 li x quon g lipshitz hd morris q predicting in vivo binding sites of rna - binding proteins using mrna secondary structure rna 2010 16 1096 10.1261 / rna.2017210 20418358 lu zj mathews dh efficient sirna selectrion using hybridization thermodynamics nucleic acids res 2007 36 640 10.1093 / nar / gkm920 18073195 tafer h ameres sl obernosterer g gebeshuber ca schroeder r martinez j hofacker il the impact of target site accessibility on the deseign of effective sirnas nat biotechnol 2008 26 578 10.1038 / nbt1404 18438400 turner dh mathews dh nndb : the nearest neighbor parameter database for predicting stability of nucleic acid secondary structure nucleic acids res 2010 38 d280 10.1093 / nar / gkp892 19880381 lorenz r bernhart sh zu siederdissen ch tafer h flamm c stadler pf hofacker il viennarna package 2.0 algorithms mol biol 2011 6 26 10.1186 / 1748 - 7188 - 6 - 26 22115189 sanders j kandrot e cuda by example : an introduction to general - purpose gpu programming 2011 boston : addison - wesley farber rm topical perspective on massive threading and parallelism j mol graph model 2011 30 82 21764615 gotz aw williamson mj xu d poole d le grand s walker rc routine microsecond molecular dynamics simulations with amber on gpus .
1. generalized born j chem theory comput 2012 8 1542 10.1021 / ct200909j 22582031 rizk g lavenier d gpu accelerated rna folding algorithm lect notes comput sci 2009 5544 1004 10.1007 / 978 - 3 - 642 - 01970 - 8 _ 101 lei g dou y wan w xia f li r ma m zou d cpu - gpu hybrid accelerating the zuker algorithm for rna secondary structure prediction applications bmc genomics 2012 13 suppl 1 s14 10.1186 / 1471 - 2164 - 13 - s1 - s14 22369626 mathews dh disney md childs jl schroeder sj zuker m turner dh incorporating chemical modification constraints into a dynamic programming algorithm for prediction of rna secondary structure proc natl acad sci usa 2004 101 7287 10.1073 / pnas.0401799101 15123812 kim j walter ae turner dh thermodynamics of coaxially stacked helices with ga and cc mismatches biochemistry 1996 35 13753 10.1021 / bi960913z 8901517 mathews dh using an rna secondary structure partition function to determine confidence in base pairs predicted by free energy minimization rna 2004 10 1178 10.1261 / rna.7650904 15272118 lu zj gloor jw mathews dh improved rna secondary structure prediction by maximizing expected pair accuracy rna 2009 15 1805 10.1261 / rna.1643609 19703939 bellaousov s mathews dh probknot : fast prediction of rna secondary structure including pseudoknots rna 2010 16 1870 10.1261 / rna.2125310 20699301 harmanci ao sharma g mathews dh parts : probabilistic alignment for rna joint secondary structure predcition nucleic acids res 2008 36 2406 10.1093 / nar / gkn043 18304945 harmanci ao sharma g mathews dh stochastic sampling of the rna structural alignment space nucleic acids res 2009 37 4063 10.1093 / nar / gkp276 19429694 harmanci ao sharma g mathews dh efficient pairwise rna structure prediction using probabilistic alignment constraints in dynalign bmc bioinformatics 2011 27 626 10.1093 / bioinformatics / btq726 seetin mg mathews dh turboknot : rapid prediction of conserved rna secondary structures including pseudoknots bioinformatics 2012 28 792 10.1093 / bioinformatics / bts044 22285566 reuter js mathews dh rnastructure : software for rna secondary structure prediction and analysis bmc bioinformatics 2010 11 129 10.1186 / 1471 - 2105 - 11 - 129 20230624 sprinzl m vassilenko ks compilation of trna sequences and sequences of trna genes nucleic acids res 2005 33 d139 10.1093 / nar / gni140 15608164 szymanski m barciszewska mz barciszewski j erdmann va 5s ribosomal rna database y2k nucleic acids res 2000 28 166 10.1093 / nar / 28.1.166 10592212 cannone jj subramanian s schnare mn collett jr d'souza lm du y feng b lin n madabusi lv muller km pande n shang z yu n gutell rr the compariative rna web ( crw ) site : an online databae of comparative sequence and structure information for ribosomal , intron , and other rnas bmc bioinformatics 2002 3 2 10.1186 / 1471 - 2105 - 3 - 2 11869452 cate jh gooding ar podell e zhou k golden bl kundrot ce cech tr doudna ja crystal structure of a group i ribozyme domain : principles of rna packing science 1996 273 1678 10.1126 / science.273.5282.1678 8781224 larsen n samuelsson t zwieb c the signal recognition particle database ( srpdb ) nucleic acids res 1998 26 177 10.1093 / nar / 26.1.177 9399828 mathews dh banerjee a r luan d d eickbush th turner dh secondary structure model of the rna recognized by the reverse transcriptase from the r2 retrotransposable element rna 1997 3 1 8990394 michel f umesono k ozeki h comparative and functional anatomy of group ii catalytic introns - - a review gene 1989 82 5 10.1016 / 0378 - 1119 ( 89 ) 90026 - 7 2684776 staunton de marlin sd stratowa c dustin ml springer ta primary structure of icam - 1 demonstrates interaction between members of the immunoglobulin and integrin supergene families cell 1988 52 925 10.1016 / 0092 - 8674 ( 88 ) 90434 - 5 3349522 adachi a gendelman he koenig s folks t willey r rabson a martin ma production of acquired immunodeficiency syndrome - associated retrovirus in human and nonhuman cells transfected with an infectious molecular clone j virol 1986 59 284 3016298 xia t burkhard me kierzek r schroeder sj jaio x cox c turner dh santa lucia j jr thermodynamic parameters for an expanded nearest - neighbor model for formation of rna duplexes with watson - crick pairs biochemistry 1998 37 14719 10.1021 / bi9809425 9778347 zuker m on finding all suboptimal foldings of an rna molecule science 1989 244 48 10.1126 / science.2468181 2468181 layton dm bundschuh r a statistical analysis of rna folding algorithms through thermodynamic parameter perturbation nucleic acids res 2005 33 519 10.1093 / nar / gkh983 15673712