health res policy syst health res policy syst health research policy and systems 1478 - 4505 biomed central london 25552272 4292987 367 10.1186 / 1478 - 4505 - 13 - 3 research does health intervention research have real world policy and practice impacts : testing a new impact assessment tool cohen gillian gm @ dvnswsm.org.au schroeder jacqueline jschroeder @ iprimus.com.au newson robyn robynpaul2725 @ optusnet.com.au king lesley lesley.king @ sydney.edu.au rychetnik lucie lucie.rychetnik @ sydney.edu.au milat andrew j amila @ doh.health.nsw.gov.au bauman adrian e adrian.bauman @ sydney.edu.au redman sally sally.redman @ saxinstitute.org.au chapman simon simon.chapman @ sydney.edu.au school of public health , university of sydney , edward ford building ( a27 ) , fisher rd , sydney , nsw 2006 australia prevention research collaboration , school of public health , university of sydney , level 6 , building d17 , sydney , nsw 2006 australia school of medicine , university of notre dame , 160 oxford street , darlinghurst sydney , nsw 2010 australia centre for epidemiology and evidence , nsw ministry of health , level 7 , 73 miller st , north sydney , nsw 2060 australia sax institute , level 13 , building 10 , 235 jones street , ultimo , nsw 2007 australia 1 1 2015 1 1 2015 2015 13 3 14 10 2014 11 12 2014 ( c ) cohen et al. ; licensee biomed central .
2014 this article is published under license to biomed central ltd .
this is an open access article distributed under the terms of the creative commons attribution license ( http :// creativecommons.org / licenses / by / 4.0 ) , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly credited .
the creative commons public domain dedication waiver ( http :// creativecommons.org / publicdomain / zero / 1.0 /) applies to the data made available in this article , unless otherwise stated .
background there is a growing emphasis on the importance of research having demonstrable public benefit .
measurements of the impacts of research are therefore needed .
we applied a modified impact assessment process that builds on best practice to 5 years ( 2003 - 2007 ) of intervention research funded by australia 's national health and medical research council to determine if these studies had post - research real - world policy and practice impacts .
methods we used a mixed method sequential methodology whereby chief investigators of eligible intervention studies who completed two surveys and an interview were included in our final sample ( n = 50 ) , on which we conducted post - research impact assessments .
data from the surveys and interviews were triangulated with additional information obtained from documentary analysis to develop comprehensive case studies .
these case studies were then summarized and the reported impacts were scored by an expert panel using criteria for four impact dimensions : corroboration ; attribution , reach , and importance .
results nineteen ( 38 %) of the cases in our final sample were found to have had policy and practice impacts , with an even distribution of high , medium , and low impact scores .
while the tool facilitated a rigorous and explicit criterion - based assessment of post - research impacts , it was not always possible to obtain evidence using documentary analysis to corroborate the impacts reported in chief investigator interviews .
conclusions while policy and practice is ideally informed by reviews of evidence , some intervention research can and does have real world impacts that can be attributed to single studies .
we recommend impact assessments apply explicit criteria to consider the corroboration , attribution , reach , and importance of reported impacts on policy and practice .
impact assessments should also allow sufficient time between impact data collection and completion of the original research and include mechanisms to obtain end - user input to corroborate claims and reduce biases that result from seeking information from researchers only .
keywords intervention research policy research impact research translation issue - copyright - statement ( c ) the author ( s ) 2015 background since the 1980s there has been a growing expectation that health research will have direct social and economic utility and impact [ 1 - 5 ] .
health intervention research , in particular , which uses scientific methods to produce knowledge about treatments , services , programs , or strategies that aim to protect , promote , or improve health , is assumed to hold immediate promise for influencing and improving future policy and practice [ 2 , 6 ] .
research funding submissions require applicants to predict the practical benefits that might flow from their planned studies [ 7 , 8 ] .
however , a large proportion of funded research fails to translate into real world solutions [ 6 , 9 - 12 ] .
over 90 different terms are used to describe research impact on policy and practice [ 13 ] , including translation , diffusion , adoption , adaptation , uptake , exchange , research utilization , and research implementation .
how and to what extent research is translated into policy and practice is emerging as an important field of research [ 14 , 15 ] .
a key area within this field is assessment of impact , or how to measure the dividends from research [ 14 , 16 ] .
in practice , assessments of research impacts are mostly commissioned by governments to determine the public benefit from research spending [ 4 , 15 , 17 ] .
governments are increasingly signaling that research metrics of research quality are insufficient to determine research value because they say little about real - world benefits of research [ 3 , 4 , 7 ] .
to date , gold standards in the assessment of research impact combine case study narratives with relevant qualitative and quantitative indicators [ 4 , 16 - 18 ] .
the impact assessment literature universally calls for expanded measures to better assess the nature and quality of real world impacts , as well as better predictive measures of longer term benefits [ 4 , 14 ] .
" the holy grail is to find short term indicators that can be measured before , during or immediately after the research is completed and that are robust predictors of the longer term impact ... from the research " [ 14 ] .
in this paper , we build on the existing literature to propose an expanded ' impact assessment ' framework , and apply a model which builds on current best practice to 5 years ( 2003 - 2007 ) of intervention research funded by australia 's peak health and medical research funding agency , the national health and medical research council ( nhmrc ) [ 15 , 18 - 24 ] .
our primary aims were to i ) pilot a modified impact assessment process and ii ) determine what proportion of intervention projects had any demonstrable impact on subsequent policy or practice in ' real world ' settings after the research undertaken had concluded and to group these projects according to the magnitude their impacts .
the project was approved by the university of sydney human research ethics committee ( 15003 ) .
methods conceptual framework a number of approaches have been developed to describe the impacts of research [ 15 ] .
the payback framework [ 19 , 24 ] and its adaptation into the canadian framework [ 20 ] are the most widely used [ 15 ] .
these approaches and the literature underpinning them indicate that it is important for impact assessment to distinguish between different types and stages of impact and to draw on multiple sources of data .
a conceptual framework can help organize data collection , analysis , and reporting to promote clarity and consistency in the impact assessments made .
it is important to acknowledge that such a model facilitates impact assessment rather than being a precise model of how research impact occurs [ 25 ] .
the primary focus of our study was to examine the policy and practice impacts of research that occur in the ' real world ' after the research had concluded .
we combined and adapted the payback and canadian frameworks to produce a conceptual model that would best fit our purpose .
we grouped different types of impacts into four levels of impact that might arise from intervention research : i ) scholarly outputs ; ii ) translational outputs ; iii ) policy or practice impacts ; and iv ) long - term population outcomes .
each impact level was populated with sub - categories or indicators to further facilitate assessment of the type of impacts that occur at each level ( figure 1 ) .
for comparison with our approach , the payback categories are included in figure 1 alongside the impact levels we describe .
figure 1 comparing categories of research impacts across models .
* the dark grey shaded areas represent the impacts of relevance to this study .
we considered that the scholarly outputs , such as publications , acquisition of new research funding , and research capacity building , were not real - world impacts as we had defined them and therefore they are not reported here ; others have made a similar distinction [ 21 ] .
translational outputs were defined as those activities that occur beyond research publication and are designed to facilitate uptake of study findings in real - world settings .
these outputs may be activities undertaken by researchers , their institutions , or government programs to facilitate knowledge uptake such as implementation protocols , training workshops , and information exchange meetings .
they may also be part of a general dissemination strategy conducted at the end of a study .
these outputs may or may not lead to policy or practice impacts and long - term population changes .
while some impacts at this level , particularly those related to information packaging for implementation , are included as part of our impact assessment here , we considered these to be of lesser importance than policy or practice impacts .
policy or practice impacts were defined as demonstrable changes , or benefits to products , processes , policies , and or practices , that occur after a research project has concluded .
these impacts are concrete , measurable changes in policy or practice such as a new government policy , a change in organizational or clinical practice , a health education campaign or related new funding that can be attributed to the research intervention in question .
impacts at this level could also include stopping or changing existing interventions following demonstration of intervention ineffectiveness .
policy or practice impacts can be widespread or localized , and may benefit specific or general populations .
impacts at this level are our primary focus in this paper .
finally , we defined long - term population outcomes as changes in health behaviors and health outcomes , such as disease incidence , prevalence , or other health indicators , or as improvements in social or economic outcomes .
such changes rarely occur quickly , and they may be difficult to attribute to health intervention research , let alone to single studies [ 9 , 15 ] .
due to these attribution issues and the distal nature of population outcomes , outcomes at this level were not assessed in our research .
as in other frameworks [ 20 , 24 ] , our model ( figure 1 ) reflects a sequence of impacts ( while recognizing that this will often not occur ) and distinguishes immediate research outputs from impacts which tend to occur later and beyond the research setting or context .
models with sequential stages assume that an impact or output at one stage may , or may not , lead to increasingly concrete and widespread impacts over time .
sampling our sample of intervention research studies was generated from a list provided by the nhmrc of 721 primary research grants that were potentially intervention - related ( as identified by the nhmrc from their records ) which commenced between 2003 and 2007 .
studies were included in our sample if they met our definition of intervention research ( i.e. , any form of trial or evaluation of a service , program , or strategy aimed at disease , injury , or mental health prevention , health promotion or psychotherapeutic intervention , conducted with general or special populations , or in clinical or institutional settings ) , if the study commenced before 2007 , and if the study data had been collected and analyzed before we began our data collection in 2012 .
clinical trials of potentially prescribable drugs , vaccines , and diagnostic tests were excluded because of the very different trajectories that such therapeutic goods are required to navigate before being authorized for use by the australian therapeutic goods administration .
we determined if studies met our inclusion criteria initially by reviewing grant documents and publications , after which 83 studies were included in our sample , and then by surveying the chief investigators ( cis ) , after which 13 studies from our initial sample were found to be ineligible , leaving 70 eligible studies .
we chose to include intervention studies commencing between 2003 and 2007 in our sample because this 5 - year window provided a balance between allowing projects sufficient time post - study completion to have realized real - world impacts by the time of our data collection in 2012 and to minimize recall bias about grants that finished too long ago .
our study used a mixed methods sequential methodology .
cis were invited to complete two surveys and an interview ( figure 2 ) .
only those cis who completed both surveys and the interview were included in our final sample ( n = 50 ) .
figure 2 overview of study methods .
preparing case studies to determine impacts in order to determine if the studies had included real - world impacts relevant to our study we collected data from multiple data sources ( figure 2 and described below ) which were triangulated to produce case studies .
the case studies were reviewed by two authors and either classified as having at least one impact or no impacts .
data sources online survey an online survey ( see http :// hdl.handle.net / 2123 / 9864 ) was sent to study cis to elicit their views about the potential influence and significance of their research findings and any impacts of their research in the real world following the research project .
they were also asked questions on contextual factors and research characteristics known to be influential in practice uptake .
independent confirmation of results information about the research findings of each study was considered to be essential in determining the extent to which the reported post - study impacts could be attributed to the specific research projects under consideration .
rather than only relying on outcomes reported by the cis , which may have been subject to responders' bias and selective recall [ 26 ] , the information related to the study findings included in the case studies was subject to a separate verification process .
this involved developing a summary for each study based on published results related to the principal study outcomes which was then reviewed by a panel of authors .
the panel classified interventions according to whether there were statistically significant changes on principal outcomes : those that did , those with ' mixed ' results ( in cases where there were significant changes for some but not all principal outcomes or if unintended or ancillary results were emphasized over the primary focus of the original research questions ) , and those where the intervention did not produce statistically significant changes .
in some cases , no published results related to the principal outcomes could be found .
the panel was not asked to make judgments in relation to the quality of the research , the appropriateness of the research methods , or the importance of the findings .
in this assessment and verification step , ' statistical significance ' provided a simple and objective way of considering study outcomes , and was not intended as a measure of the clinical or societal value of the outcome .
semi - structured interviews semi - structured ' conversational ' interviews were customized for each study based on responses to the online survey .
the interviewers sought to obtain more information about any claimed real - world impacts of the study and to explore the cis perceptions of what had helped or hindered the uptake of their intervention .
interviews covered the following themes : i ) implications : what are they and have any come into effect ? ; ii ) impacts : what occurred , and why do you think some impacts occurred , while others did not ? ; iii ) engagement with potential end - users ( research team and other stakeholders ) before , during , and after the study ; iv ) communication before , during , and after the completion of the study ; v ) contribution to knowledge : what was the nature of any contribution ? ; and vi ) follow - up : what occurred following the post - research dissemination ?
document analysis to corroborate reported impacts the impacts reported by the cis were corroborated , where possible , by completing an internet search using google to search for relevant web pages , newsletters , media releases , or other documents .
piloting the impact scoring tool we sought to pilot an impact scoring process so that we could group and compare studies according to the magnitude of their impact .
this process included the following steps : preparing impact assessment summaries the detailed case studies that included real - world impacts relevant to our study ( n = 19 ) were used to develop a two to three page impact assessment summary for consideration by an expert panel .
a common format was used to allow comparison between cases .
the summaries included the study aims and research question / s , a description of the intervention , the study findings , post - study impacts that potentially met our definition of policy and practice impacts ( only impacts that had actually occurred rather than those that could potentially occur in the future were included ) , evidence of independent corroboration and attribution of impacts , any contextual factors that may have had an influence on impact , and a summary of information and evidence related to each of our scoring criteria ( corroboration , attribution , reach , and importance ) for each of the reported impacts ( see scoring of impacts below ) .
convening an expert panel an expert panel made up of 12 experienced intervention researchers from the fields of public health , health policy , and clinical medicine , 6 of whom were external to the project , was convened to review and assess the impact assessment summaries and provide an overall assessment of the policy and practice impact of each of study .
four panelists were former or current government health policy makers .
as the studies being assessed were heterogeneous in terms of the topic area they addressed , it was not possible to convene a panel made up of content experts .
panelists were therefore selected because of their intervention research expertise and their knowledge of how evidence is translated into policy and practice .
none of the panelists had been involved in the studies being assessed .
to introduce the session , the panel was briefed on our study methods .
they were also introduced to our conceptual framework and provided with our definition of policy and practice impacts .
each case study was then presented in turn .
after each presentation , panelists were given an opportunity to ask clarifying questions before scoring impact for that case .
panel members were provided with the case summaries in advance and hard copies of these were made available to the panelists for reference during the panel proceedings .
panel proceedings were completed over the course of a single day .
scoring of impacts the conceptual framework ( figure 1 ) was used to focus the panel 's attention on the impacts of interest for our study during the scoring process .
only impacts that were consistent with the categories of interest within this model were scored .
the combined impacts of each case were scored using a modification of the scoring tool used by the australian excellence in innovation ( eii ) trial [ 22 ] and the uk 's research excellence framework trials [ 27 , 28 ] .
the original processes considered intervention reach combined with significance of impact ; however , a recommendation from the eii trial was that reach and impact significance should be judged separately to avoid biasing small studies [ 22 ] .
the need for also considering corroboration and attribution of claimed impacts has been repeatedly emphasized in the literature [ 4 , 14 , 16 , 17 , 22 ] .
based on these recommendations we developed a scoring system that included four dimensions of impact , namely corroboration , attribution , reach , and importance .
importance was used as it was felt the term significance may be confused with the statistical significance of the study findings rather than the importance of the reported impacts .
our scoring system consisted of a series of questions considered by the panelists when scoring each dimension of impact and a rating system based on a likert scale of 1 to 9 for scoring each dimension ( table 1 ) .
we also provided panelists with specific instructions in relation to scoring each dimension .
for example , we instructed the panel to judge reach of the impacts against what was possible for the relevant target population , not against other interventions with different potential , and to judge importance of the impacts claimed by referring to the definition and examples in the scale .
using this information as a guide , panelists were asked to score the overall impact of each study , independently , using hand held keypad transmitters .
table 1 scoring system independent corroboration attribution reach importance did the materials provided to verify the research impact convince the panel that the key impact claims had been corroborated ? was the link between the research and the claimed post - research impact clearly demonstrated ?
how broad was the reach of the impacts on the relevant constituencies , when reach is defined as spread and breadth of influence post - study ?
how important are the post - research impacts to products , processes , behaviors , policies , and / or practices , when importance is defined the significance and noteworthiness of an impact and its ability to endure ?
8 - 9 - corroborated 8 - 9 - significant contribution 8 - 9 - extensive reach because it has widespread reach in relevant constituencies in multiple countries 8 - 9 - extremely important 6 - 7 - probably corroborated 6 - 7 - good contribution 6 - 7 - broad reach because it has widespread reach in relevant constituencies across multiple regions , or states , in australia or internationally 6 - 7 - very important 5 - possibly or partially corroborated 5 - moderate contribution 5 - moderate reach because it is reaching relevant constituencies in multiple discrete locations 5 - moderately important 3 - 4 - not corroborated but further information could provide a more convincing corroboration 3 - 4 - small or some contribution 3 - 4 - some reach ( modest ) because the impact has only modest reach in local constituencies , or has continued in the areas where the study was conducted 3 - 4 - some import 1 - 2 - not corroborated and it is unlikely that further information could provide a more convincing corroboration 1 - 2 - there is no discernible link between the underpinning research and the claimed post - study research 1 - 2 - limited or no assessable post - study reach 1 - 2 - limited or no assessable post - study importance data analysis the results from the panel were analyzed by examining the distribution of scores as group means and standard deviations for each question , as well as a measure of spread of responses ( coefficient of variation , standard deviation / mean ) .
the distribution was also categorized into tertiles : low , medium , and high impacts .
results response rate a total of 50 cis completed both surveys and an interview , providing a response rate of 71 % ( 50 out of a possible 70 eligible studies ). of the 20 cis that did not respond , 3 did not return survey 1 ( 83 sent ; 7 confirmed as ineligible ) , 11 did not respond after receiving survey 2 ( 73 sent ; 6 confirmed as ineligible ) , and 6 did not respond to a request for interview ( 56 invitations sent ) .
number of studies with impacts and other study characteristics thirty - one studies ( 62 %) were classified as having no real - world impacts and 19 ( 38 %) were assessed as having at least one impact .
the 50 studies included in our overall sample represent a diverse range of intervention research projects .
just over a third ( 36 %) were primary prevention or health promotion interventions ; 24 % were early intervention or screening interventions ; and 40 % were interventions related to the treatment or management of an illness , disease , or disorder .
table 2 provides an overview of the topic areas addressed by the studies within each of these intervention groups for impact and no impact categories .
the proportion of primary prevention or health promotion interventions in the no impact group ( n = 15 ; 48 %) was greater than that for the impact group ( n = 3 ; 16 %) .
table 2 type of interventions included in our sample by impact category ( n = 50 ) impact category primary prevention / health promotion early intervention / screening treatment / management of an illness / disease / disorder n = 18 ( 36 %) n = 12 ( 24 %) n = 20 ( 40 %) no impact n = 15 ( 48 %)* n = 5 ( 16 %) n = 11 ( 36 %) n = 31 ( 62 %) adolescent mental health childhood obesity alcohol misuse alcohol family violence allergy / asthma allergy prevention parenting skills anorexia childhood injury ( atsi ) premature infants arthritis ( 2 ) childhood obesity ( low ses ) suicide sud asthma falls prevention ( 3 ) cancer ( 2 ) healthy ageing ( 2 ) diabetes hospital acquired infection post - traumatic stress sports injuries renal disease tobacco ( atsi ) ( 2 ) tobacco ( cald ) impact n = 3 ( 16 %)* n = 7 ( 37 %) n = 9 ( 47 %) n = 19 ( 38 %) adolescent health bowel cancer ( 2 ) anorexia falls prevention ( 2 ) chronic disease ( atsi ) arthritis ( 2 ) language delay childhood obesity maternal & infant health dental decay parenting skills ( 2 ) depression neck pain obsessive compulsive disorder post - traumatic stress * fishers exact test p = 0.03 .
atsi , aboriginal and torres strait islander ; cald , culturally and linguistically diverse ; ses , socio - economic status ; sud : substance use disorder .
the funding period for the studies in our final sample ranged from 1 to 4 years , with the mean funding period being 2 years .
a large proportion ( n = 20 ; 40 %) of studies in our sample did not commence until 2007 , the final year in our study period ( 2003 - 2007 ) .
for most of the studies ( 88 % ; n = 44 ) , the grant funding period concluded by 2009 , while the funding period for all of the studies ( n = 50 ) had concluded by 2011 .
the pattern in terms of number of studies by year in which the funding was completed was similar for the impact and no impact categories .
results of the impact scoring tool pilot spread of impact scores for the studies assessed as having impacts ( n = 19 ) , the mean impact scores ( n = 12 raters ) and 95 % confidence intervals for each of the impact dimensions within our scoring system ( corroboration , attribution , reach , and importance ) are provided in table 3 .
responses for each dimension were ranked and divided into tertiles and summarized across dimension in the far right column , as low ( n = 6 ) , medium ( n = 7 ) , and high ( n = 6 ) impact groups .
the four dimensions were not summed to provide a total score for each study as we considered that each dimension should remain as a separate consideration .
however , there was general concordance in the ranking of each study across dimensions .
the mean scores across cases showed substantial variation , which allowed scores to be categorized into tertiles and these were examined for differences in magnitude of impact between studies figure 3 .
table 3 mean impact scores for projects with impact ( n = 19 ) corroboration attribution reach importance impact score groups mean * 95 % ci mean * 95 % ci mean * 95 % ci mean * 95 % ci 4.6 ( 3.5 - 5.7 ) 6.0 ( 5.1 - 6.9 ) 3.1 ( 2.3 - 3.9 ) 2.4 ( 1.7 - 3.2 ) low 5.0 ( 4.2 - 5.8 ) 5.0 ( 4.3 - 5.7 ) 4.9 ( 4.4 - 5.4 ) 4.7 ( 4.0 - 5.3 ) low 3.2 ( 2.8 - 5.5 ) 3.0 ( 2.5 - 3.5 ) 3.3 ( 2.7 - 4.0 ) 3.6 ( 2.6 - 4.5 ) low 3.0 ( 2.3 - 3.7 ) 2.8 ( 1.9 - 3.5 ) 3.2 ( 2.5 - 3.8 ) 2.8 ( 1.9 - 3.6 ) low 5.3 ( 4.0 - 6.6 ) 3.3 ( 2.6 - 3.9 ) 2.9 ( 1.9 - 3.9 ) 3.1 ( 1.8 - 4.3 ) low 4.3 ( 3.1 - 5.6 ) 4.8 ( 3.5 - 6.0 ) 3.1 ( 2.3 - 3.9 ) 3.2 ( 2.5 - 3.9 ) low 5.8 ( 4.8 - 6.8 ) 6.3 ( 5.6 - 6.9 ) 4.4 ( 3.9 - 4.9 ) 4.4 ( 3.7 - 5.2 ) medium 4.1 ( 3.5 - 4.7 ) 5.7 ( 4.7 - 6.8 ) 4.8 ( 4.2 - 5.4 ) 5.4 ( 4.3 - 6.4 ) medium 7.1 ( 6.5 - 7.7 ) 7.3 ( 6.5 - 8.0 ) 4.7 ( 3.9 - 5.5 ) 4.8 ( 3.7 - 6.0 ) medium 6.0 ( 5.3 - 6.7 ) 5.8 ( 5.0 - 6.5 ) 6.5 ( 5.6 - 7.4 ) 5.0 ( 4.2 - 5.8 ) medium 5.3 ( 4.4 - 6.1 ) 5.5 ( 4.5 - 6.5 ) 5.2 ( 4.4 - 5.9 ) 6.0 ( 5.2 - 6.8 ) medium 7.3 ( 6.5 - 8.2 ) 6.7 ( 6.7 - 7.7 ) 4.0 ( 3.53 - 4.5 ) 4.3 ( 3.6 - 4.9 ) medium 6.6 ( 5.7 - 7.8 ) 5.2 ( 4.3 - 6.0 ) 5.2 ( 4.4 - 5.92 ) 4.4 ( 4.0 - 4.8 ) medium 7.9 ( 7.3 - 8.5 ) 7.8 ( 7.9 - 8.3 ) 6.3 ( 5.9 - 6.6 ) 7.2 ( 6.5 - 7.8 ) high 6.8 ( 6.2 - 7.4 ) 7.2 ( 6.5 - 7.8 ) 5.8 ( 4.9 - 6.6 ) 6.4 ( 5.7 - 7.2 ) high 7.4 ( 6.6 - 8.2 ) 7.6 ( 6.9 - 8.3 ) 7.3 ( 6.6 - 7.9 ) 6.3 ( 5.5 - 7.2 ) high 6.5 ( 5.8 - 7.2 ) 6.1 ( 5.3 - 6.9 ) 6.0 ( 5.1 - 6.9 ) 6.5 ( 5.7 - 7.3 ) high 8.3 ( 7.8 - 8.7 ) 7.6 ( 7.2 - 8.0 ) 7.1 ( 6.5 - 7.7 ) 7.0 ( 6.3 - 7.6 ) high 7.1 ( 6.5 - 7.6 ) 6.7 ( 5.9 - 7.4 ) 6.1 ( 5.5 - 6.7 ) 5.8 ( 4.9 - 6.6 ) high * 12 raters .
ci , confidence interval .
figure 3 mean impact scores for projects with impact for each impact dimension ( n = 19 ) .
distribution of responses among raters the coefficient of variation between raters' scores for each grant within each impact dimension was generally small , indicating that there was a high degree of consistency of scores between raters .
the variation for ratings was less than 0.25 for all of the projects in the high ( n = 6 ) and medium level ( n = 7 ) impact groups .
however , it ranged from 0.39 to 0.41 in the low impact group ( n = 6 ) , indicating that there was less agreement between raters for these studies , which tended to have less corroborative evidence about impact , or were assessed as being closer to traditional research metric impacts than to policy and practice impacts .
this showed greater spread in the distribution of panel responses in a subset of grants appraised .
type of impacts reported the type of impacts reported for the 19 studies classified as having impacts are summarized by impact score group in table 4 .
some studies reported impacts of more than one impact type ( e.g. , policy and service change ) .
half of the impacts ( n = 21 ) reported were in the form of translational outputs ( e.g. , intervention resources , including websites , publications , and manuals for end users or training ) .
although potentially useful resources for policy and practice , resources were not necessarily proof of use and we considered them to be the lowest level of impact .
where these impacts were endorsed by professional bodies or had significant reach , the impacts were considered to be of higher magnitude .
the remaining impacts ( n = 21 ) were classified as policy and practice impacts which included clinical practice changes ( n = 6 ) , service changes ( n = 9 ) , organizational changes ( n = 1 ) , commercialization of products or services ( n = 1 ) , and policy changes ( n = 4 ) .
as these all require a more substantial degree of personal or organizational change , they were considered to equate to a higher level of impact .
table 4 type of impacts by impact score group ( n = 19 ) impact category number impacts by impact category and impact score example total number impacts high impact studies ,* medium impact studies ,* low impact studies ,* n = 6 n = 7 n = 6 policy and practice impacts policy changes 3 0 1 a school - based parent education program to promote adolescent health influenced the 2011 change to the victorian liquor control reform act 1998 ( secondary supply ) 4 organizational change 1 0 0 an intervention targeting the year before and after birth in aboriginal children in remote areas led to improvements in continuity of care between the hospital system and remote community care 1 commercial product or service 1 0 0 the license for a parenting program that was shown to be effective for indigenous families was sold to a province in canada where it is still in operation and has been formally evaluated 1 service changes 4 3 2 an intervention to provide more effective communication to improve participation in bowel cancer screening led to an advanced notification letter being included in the national bowel cancer screening program in australia .
an advanced notification letter has been adopted by at least four other countries around the world 9 clinical practice changes 1 4 1 an intervention to retain the neck muscles of neck pain patients had led to changes to clinical practice 6 total number policy & practice impacts reported 21 * translational outputs professional training ( e.g. , college of practitioners ) 2 5 2 a professional development training program based on an intervention to slow progression of knee osteoarthritis was developed and delivered through peak practitioner bodies 9 professionally endorsed documentation ( guidelines , manuals ) 3 3 1 the findings from a school - based parent education program to promote adolescent health have been included in 2009 australian guidelines to reduce health risks from drinking alcohol 7 intervention resources ( websites , lay publications , training manuals ) 2 1 2 a protocol for the non - invasive management of tooth decay in private practice was endorsed for implementation at the international level by leaders in the field 5 total number translational outputs reported 21 * * each study may have had impacts within more than one impact category ( e.g. , policy change and clinical practice change , as well as professionally endorsed documentation ) .
within the group of studies ( n = 6 ) assessed by the panel to have high impacts , there was one commercial product launch , three policy changes , four changes to service delivery , one organizational change , and one change to clinical practice .
all of the studies in the high and medium impact group had at least one impact that fell within the policy and practice impact category , while only four out of six of the studies in the low impact group had impacts of this type .
none of the studies in the low and medium impact groups had more than one impact within the policy and practice category , two studies within the high impact group had three impacts each of this type , three had two impacts each of this type , and two had only one impact of this type .
many of the projects classified as having medium ( n = 7 ) and low impact ( n = 6 ) reported impacts that were anecdotal , with weak evidence that was not easily corroborated .
discussion there have been a number of studies that have examined the impacts of a set of publically funded intervention studies , where the unit of measure is an individual study .
our study differs from these in terms of its specific focus on intervention research in clinical or community settings and on measurable policy and practice impacts rather than scholarly outputs or longer term population outcomes [ 9 , 29 - 31 ] .
we chose to focus on policy and practice impacts as there is a need for reliable measures of impact to provide sound information about translation beyond the research setting , and to counter - balance the tendency to focus on research metrics as a sole indicator of impact .
other studies of health research impacts have defined their scope in terms of the content area ( e.g. , breast cancer , stroke ) [ 21 , 25 , 26 , 32 , 33 ] , or assessed the impacts of a program of research or research institution as a whole [ 22 , 23 ] .
we found that single intervention research studies can and do have concrete and measurable post - research real - world impacts , with 38 % of the studies in our sample demonstrating some impacts on policy and practice .
the impacts were often multiple and diverse , covering all of the categories of interest within our research impacts model ( figure 1 ) .
we also found that the magnitude of impact varied between studies .
studies received lower impact scores where their impacts involved the development of resources and training , rather than concrete changes to policy and practice and / or because evidence to corroborate the researcher 's claims about impact was weak or could not be found .
when the studies were divided into tertiles , three almost equal groups ( high , medium , and low impact ) were formed .
in this paper we do not discuss why some studies had impact and others did not .
this will be the subject of another paper .
other research has found that individual studies from a range of research types , including basic , applied , and clinical research , can have wider impacts ( outside of research settings ) [ 9 , 21 , 29 ] .
however , it is difficult to compare our findings with these previous studies due to differences in study methodologies .
for example , another australian study that examined the impacts of intervention research found moderate to high policy and practice impacts were scored in 10 out of 17 cases ( 59 %) [ 9 ] .
the remaining cases were scored as having limited impact , but the scoring system did not allow a score of zero to be recorded for the impact category .
the study also used a broader definition of policy and practice impacts than we did and reported on a more homogeneous sample of interventions .
in another study examining the impacts of cardiovascular research ( both basic and clinical ) , all of the 14 clinical cases in the sample had impacts beyond the research setting [ 33 ] .
in this study , the timeframe from when the original studies were completed to impact data collection was between 15 and 20 years .
the method we piloted resulted in a good level of agreement between raters about the extent of the post - research policy and practice impacts for most of our case studies ; there was more variability in scoring of the low impact cases .
our method also provided an estimate of the magnitude of the impact , which is important in order to compare impacts across heterogeneous studies [ 5 ] .
however , it is possible that not enough time had elapsed for all of the studies in our sample and subsequent impacts may yet occur .
it has been suggested that it can take a considerable amount of time ( up to 17 years ) for evidence to be translated into practice [ 33 , 34 ] .
a considerable proportion ( 40 %) of the studies in our sample commenced in 2007 , 5 years before our data collection began in 2012 , and nearly half ( 48 %) of the studies were completed in the 3 years prior to our data collection .
it is also possible that some of the studies in our sample did not have impacts because they were only single studies .
ideally , policy and practice change should result from a summarized body of knowledge in the form of systematic reviews or research synthesis , rather than single studies alone .
it may be that it is more appropriate to apply an impact assessment process to a researcher 's body of work rather than a single research study .
this would capture impacts that cannot be attributed to a single research study and allow sufficient time for impacts to occur .
we suggest it is important to make explicit the purpose of any research impact assessment process to determine whether the unit of analysis is to be that of a single study , a researcher 's body of work , the research institution , or of a synthesis of all of the published evidence on a given topic .
while others have scored the impacts of research [ 9 , 21 , 22 , 28 , 31 ] , our scoring system is unique in that it involved scoring four separate dimensions of impact , namely corroboration , attribution , reach , and importance .
this system sought to overcome some of the issues with attribution and corroboration that had been encountered during previous assessment processes , as well as the need to distinguish reach from significance so as not to downplay the potential impact of smaller studies , or studies with small target groups [ 4 , 14 , 16 , 17 , 22 ] .
however , on reflection , panel members tended to score the importance of the impacts highly across all dimensions , compared to the benchmark examples provided in the scoring sheet .
for example , we used the impact of human papilloma virus vaccine research [ 35 , 36 ] as an example of a study that would be given a high score of nine for importance because of its global implications for prevention of a serious and prevalent disease .
none of the research studies in our sample had impacts as significant as this example , but some panel members nevertheless scored some projects at eight for importance .
the reasons for this are unclear , although it may be that something of a ceiling effect operates , with raters scoring all projects with impacts above a certain level in terms of importance on a similarly high scale .
while the scores may be comparable within any given process , further guidance to panels about appropriate magnitude of scores should be provided to support between - panel comparison .
it may also be necessary to review individual panel member scores during the panel process to ensure that all panel members are scoring impacts based on similar considerations [ 31 ] .
having a system for scoring cases according to the level of corroborating evidence and degree of evidence for attribution was beneficial .
however , it was not possible to find supporting information of acceptable quality for all of the studies in our sample .
there was a greater degree of variability in panel scores where limited supporting information was available or it was absent .
to improve reliability of scoring , it may be necessary to mark case summaries without adequate supportive evidence as ' unclassified ' [ 23 ] and not score these cases until supporting evidence becomes available .
another way to verify claims made by cis would be to supplement publicly available information with third party interviews of end - users .
this is a resource - intensive process [ 16 ] and for this reason few examples where interviews or surveys of end users are used as part of impact assessment processes can be found [ 9 , 37 ] .
to improve the feasibility of this approach , we suggest that end user input should ideally be sought post - panel assessment , so that resources are expended on impacts of potential significance .
reliance on only the perspectives of researchers is problematic for other reasons .
researchers may sometimes be unaware of post - research impacts of their research , because research impact is seldom a key research performance measure , so they do not actively track uptake , or because they consider that their role finishes with publication [ 4 ] .
this may result in research impacts being under - reported [ 26 , 29 , 30 , 32 ] .
researchers may also differ in the way they conceptualize and explain the impact of their research compared to other groups [ 38 ] .
in addition , societal importance is a very difficult concept to judge .
therefore , contributors to impact assessment research and impact assessment panels should include as wide a cross section of viewpoints as possible [ 3 , 4 , 22 ] .
while our panel included both researchers and practitioners ( policy and clinical ) , limited resources meant that it was still predominantly made up of researchers .
the australian eii trial exemplified end - user participation , with expert panels comprising 70 % end users [ 22 ] .
we recommend that future studies include assessment panels made up of a predominance of non - researchers , and a high mix of different stakeholders .
conclusions there is a growing sense outside , and increasingly inside , the research sector that health intervention research is not an ' end in itself ' , and needs to have demonstrable public benefit .
in order to demonstrate this benefit , we need to have a means of measuring the impacts of research .
moreover , if such methods are to be widely used in practice by research funders and academic institutions to assess research impacts , the right balance between comprehensiveness and feasibility must be struck .
this study builds on current best practice for assessing real - world policy and practice impacts and demonstrates a systematic and multidimensional approach to impact assessment .
the findings of this study could help funding systems determine how to assess impact in the future ; however , the methods we employed were resource intensive .
further research to refine the process so that it may be more feasibly applied on a routine basis is warranted .
abbreviations ci chief investigator eii australian excellence in innovation ( eii ) trial nhmrc national health and medical research council .
competing interests the authors declare that they have no competing interests .
authors' contributions the study was co - conceived by all of the authors except rn. all of the authors except rn participated in the design of the study .
gc and js led data collection and analysis .
all of the other authors participated in the analysis and interpretation of the data .
gc and rn led the drafting the manuscript .
all of the other authors contributed to the drafting of the manuscript .
all of the authors have read and approved the final manuscript .
acknowledgements this work was supported by funding from the national health and medical research council of australia ( grant # 1024291 ) .
the authors would like to thank the study participants for their time and contribution to this research .
references 1 .
denholm em martin wj translational research in environmental health sciences transl res 2008 151 57 58 10.1016 / j.trsl.2007.09.005 18201672 2 .
erno - kjolhede e hansson f measuring research performance during a changing relationship between science and society res eval 2011 20 131 143 10.3152 / 095820211x12941371876544 3 .
frodeman r holbrook jb science 's social effects issues sci technol 2007 23 28 30 4 .
bornmann l measuring the societal impact of research eur mol biol organ j 2012 13 673 676 5 .
martin br the research excellence framework and the ' impact agenda ' : are we creating a frankenstein monster ?
res eval 2011 20 247 254 10.3152 / 095820211x13118583635693 6 .
grimshaw jm eccles mp lavis jn hill sj squires je knowledge translation of research findings implement sci 2012 7 1748 5908 10.1186 / 1748 - 5908 - 7 - 50 7 .
holbrook jb frodeman rj holbrook b mitcham c xiaonan h re - assessing the science - society relation : the case of the us national science foundation 's broader impacts merit review criterion ( 1997 - 2011 ) peer review , research integrity , and the governance of science - practice , theory , and current discussion 2012 dalian people 's publishing house and dalian university of technology 328 362 8 .
henshall c the impact of payback research : developing and using evidence in policy res eval 2011 20 257 258 10.3152 / 095820211x13118583635873 9 .
milat a laws r king l newson r rychetnik l rissel c bauman a redman s bennie j policy and practice impacts of applied research : a case study analysis of the new south wales health promotion demonstration research grants scheme 2000 - 2006 health res policy sys 2013 11 5 10.1186 / 1478 - 4505 - 11 - 5 10 .
glasgow re emmons km how can we increase translation of research into practice ?
types of evidence needed annu rev public health 2007 28 413 433 10.1146 / annurev.publhealth.28.021406.144145 17150029 11 .
bhattacharyya ok estey ea zwarenstein m methodologies to evaluate the effectiveness of knowledge translation interventions : a primer for researchers and health care managers j clin epidemiol 2011 64 32 40 10.1016 / j.jclinepi.2010.02.022 21130349 12 .
brownson rc kreuter mw arrington ba true wr translating scientific discoveries into public health action : how can schools of public health move us forward ?
public health rep 2006 121 97 103 16416704 13 .
buykx p humphreys j wakerman j perkins d lyle d mcgrail m kinsman l ' making evidence count ' : a framework to monitor the impact of health services research aust j rural health 2012 20 51 58 10.1111 / j.1440 - 1584.2012.01256.x 22435764 14 .
buxton m the payback of ' payback ' : challenges in assessing research impact res eval 2011 20 259 260 10.3152 / 095820211x13118583635837 15 .
banzi r moja l pistotti v facchini a liberati a conceptual frameworks and empirical approaches used to assess the impact of health research : an overview of reviews health res policy syst 2011 9 26 10.1186 / 1478 - 4505 - 9 - 26 21702930 16 .
donovan c state of the art in assessing research impact : introduction to a special issue res eval 2011 20 175 179 10.3152 / 095820211x13118583635918 17 .
grant j brutscher p - b kirk se butler l wooding s capturing research impacts : a review of international practice .
documented briefing 2010 santa monica , ca rand corporation 18 .
hanney sr gonzalez - block ma buxton mj kogan m the utilisation of health research in policy - making : concepts , examples and methods of assessment health res policy syst 2003 1 2 10.1186 / 1478 - 4505 - 1 - 2 12646071 19 .
hanney s packwood t buxton m evaluating the benefits from health research and development centres : a categorization , a model and examples of application evaluation 2000 6 137 160 10.1177 / 13563890022209181 20 .
graham ker chorzempa hl valentine pa magnan j evaluating health research impact : development and implementation of the alberta innovates - health solutions impact framework res eval 2012 21 354 367 10.1093 / reseval / rvs027 21 .
wooding s hanney s pollitt a buxton j project retrosight .
understanding the returns from cardiovascular and stroke research : policy report 2011 cambridge rand europe 22 .
group of eightexcellence in innovation : research impacting our nation 's future - assessing the benefits 2012 adelaide australian technology network of universities 23 .
higher education funding council for england , scottish funding council , higher education funding council for wales , department for employment and learning northern irelandresearch excellence framework impact pilot exercise findings of the expert panels 2010 london research excellence framework 24 .
buxton m hanney s how can payback from health services research be assessed ?
j health serv res 1996 1 35 43 25 .
hanney sr grant j wooding s buxton mj proposed methods for reviewing the outcomes of health research : the impact of funding by the uk 's ' arthritis research campaign ' health res policy syst 2004 2 4 10.1186 / 1478 - 4505 - 2 - 4 15272939 26 .
hanney sr watt a jones th metcalf l conducting retrospective impact analysis to inform a medical research charity 's funding strategies : the case of asthma uk allergy asthma clin immunol 2013 9 17 10.1186 / 1710 - 1492 - 9 - 17 23651523 27 .
higher education funding council for englanddecisions on assessing research impact 2011 london research excellence framework 28 .
higher education funding council for englandpanel criteria and working methods 2012 london research excellence framework 29 .
hanney s buxton m green c coulson d raftery j an assessment of the impact of the nhs health technology assessment programme health technol assess 2007 11 iii iv 10.3310 / hta11530 18031652 30 .
johnston sc rootenberg jd katrak s smith ws elkins js effect of a us national institutes of health programme of clinical trials on public health and costs lancet 2006 367 1319 1327 10.1016 / s0140 - 6736 ( 06 ) 68578 - 4 16631910 31 .
oortwijn wj hanney sr ligtvoet a hoorens s wooding s grant j buxton mj bouter lm assessing the impact of health technology assessment in the netherlands int j technol assess health care 2008 24 259 269 10.1017 / s0266462308080355 18601793 32 .
pollitt a wooding s hanney s buxton m grant j project retrosight .
understanding the returns from cardiovascular and stroke research : methodology report 2011 cambridge rand europe 33 .
donovan c butler l butt aj jones th hanney sr evaluation of the impact of national breast cancer foundation - funded research med j aust 2014 200 214 218 10.5694 / mja13.10798 24580524 34 .
grant j cottrell r cluzeau f fawcett g evaluating " payback " on biomedical research from papers cited in clinical guidelines : applied bibliometric study bmj ( clin res ed ) 2000 320 1107 1111 10.1136 / bmj.320.7242.1107 35 .
garland sm hernandez - avila m wheeler cm perez g harper dm leodolter s tang gw ferris dg steben m bryan j quadrivalent vaccine against human papillomavirus to prevent anogenital diseases n engl j med 2007 356 1928 1943 10.1056 / nejmoa061760 17494926 36 .
tay s - k cervical cancer in the human papillomavirus vaccination era curr opin obstet gyn 2012 24 3 7 10.1097 / gco.0b013e32834daed9 37 .
barber r boote jd parry gd cooper cl yeeles p cook s can the impact of public involvement on research be evaluated ?
a mixed methods study health expect 2012 15 229 241 10.1111 / j.1369 - 7625.2010.00660.x 21324054 38 .
kwan p johnston j fung ay chong ds collins ra lo sv a systematic evaluation of payback of publically funded health and health services research in hong kong bmc health serv res 2007 7 121 10.1186 / 1472 - 6963 - 7 - 121 17662157